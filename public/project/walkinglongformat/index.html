<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns#">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <title>Stream Occurence &middot; My Name</title>
        <meta name="description" content="IntroductionAccessing DataMethodsSummaryVariablesPre-processingSplitting DataGuidanceProportionBalanced?Cause and effectPrevalanceData LeakageStructuresEvaluation TechniquesModelingModel SelectionRFE Random ForestRFE GBMFFS Random ForestFFS GBMQuick IntroRFE downsizingRFE tuning Random ForestRFE tuning GBMRFE tuned partial dependency plotsFFS tuned Random ForestFFS tuning GBMModel AssessmentDiscussion/ResultsReferencesIntroductionIntroduction">
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="generator" content="Hugo 0.68.3" />
        <meta name="robots" content="index,follow">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta property="og:title" content="Stream Occurence">
<meta property="og:description" content="IntroductionAccessing DataMethodsSummaryVariablesPre-processingSplitting DataGuidanceProportionBalanced?Cause and effectPrevalanceData LeakageStructuresEvaluation TechniquesModelingModel SelectionRFE Random ForestRFE GBMFFS Random ForestFFS GBMQuick IntroRFE downsizingRFE tuning Random ForestRFE tuning GBMRFE tuned partial dependency plotsFFS tuned Random ForestFFS tuning GBMModel AssessmentDiscussion/ResultsReferencesIntroductionIntroduction">
<meta property="og:type" content="article">
<meta property="og:url" content="/project/walkinglongformat/">
        <link rel="stylesheet" href="/dist/site.css">
        <link rel="stylesheet" href="/dist/syntax.css">
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,400,600,700,300&subset=latin,cyrillic-ext,latin-ext,cyrillic">
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN" crossorigin="anonymous">
        
        
        
        
    </head>
    <body>
        
<script type="application/javascript">
var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
var doNotTrack = (dnt == "1" || dnt == "yes");
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'XXX', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>


        <div id="wrapper">
            <header class="site-header">
                <div class="container">
                    <div class="site-title-wrapper">
                        
                            <h1 class="site-title">
                                <a title="Ghostwriter example" href="/">Ghostwriter example</a>
                            </h1>
                        
                        <a class="button-square" href="/index.xml"><i class="fa fa-rss"></i></a>
                        
                            <a class="button-square button-social hint--top" data-hint="Twitter" title="Twitter" href="https://twitter.com/XXX" rel="me">
                                <i class="fa fa-twitter"></i>
                            </a>
                        
                        
                            <a class="button-square button-social hint--top" data-hint="Facebook" title="Facebook" href="https://www.facebook.com/username" rel="me">
                                <i class="fa fa-facebook"></i>
                            </a>
                        
                        
                            <a class="button-square button-social hint--top" data-hint="Gitlab" title="Gitlab" href="https://gitlab.com/XXX" rel="me">
                                <i class="fa fa-gitlab"></i>
                            </a>
                        
                        
                            <a class="button-square button-social hint--top" data-hint="Github" title="Github" href="https://github.com/XXX" rel="me">
                                <i class="fa fa-github-alt"></i>
                            </a>
                        
                        
                            <a class="button-square button-social hint--top" data-hint="Stack Overflow" title="Stack Overflow" href="https://stackoverflow.com/users/XXX/YYY" rel="me">
                                <i class="fa fa-stack-overflow"></i>
                            </a>
                        
                        
                            <a class="button-square button-social hint--top" data-hint="LinkedIn" title="LinkedIn" href="https://linkedin.com/in/XXX/" rel="me">
                                <i class="fa fa-linkedin"></i>
                            </a>
                        
                        
                            <a class="button-square button-social hint--top" data-hint="Google+" title="Google+" href="https://google.com/&#43;XXX" rel="me">
                                <i class="fa fa-google-plus"></i>
                            </a>
                        
                        
                            <a class="button-square button-social hint--top" data-hint="Email" title="Email" href="mailto:XXX@example.com">
                                <i class="fa fa-envelope"></i>
                            </a>
                        
                    </div>

                    <ul class="site-nav">
                        
    <li class="site-nav-item">
        <a title="Blog" href="/">Blog</a>
    </li>

    <li class="site-nav-item">
        <a title="Projects" href="/project/">Projects</a>
    </li>

    <li class="site-nav-item">
        <a title="Contact" href="/page/contact/">Contact</a>
    </li>

    <li class="site-nav-item">
        <a title="About" href="/page/about/">About</a>
    </li>

                    </ul>
                </div>
            </header>

            <div id="container">


<div class="container">
    <article class="post-container">
        <header class="post-header">
    <h1 class="post-title">Stream Occurence</h1>
    
</header>

        <div class="post-content clearfix">
    

    
<script src="/rmarkdown-libs/kePrint/kePrint.js"></script>

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#accessing-data">Accessing Data</a></li>
<li><a href="#methods">Methods</a><ul>
<li><a href="#summary">Summary</a></li>
<li><a href="#variables">Variables</a></li>
<li><a href="#pre-processing">Pre-processing</a></li>
<li><a href="#splitting-data">Splitting Data</a><ul>
<li><a href="#guidance">Guidance</a></li>
<li><a href="#proportion">Proportion</a></li>
<li><a href="#balanced">Balanced?</a></li>
<li><a href="#cause-and-effect">Cause and effect</a></li>
<li><a href="#prevalance">Prevalance</a></li>
<li><a href="#data-leakage">Data Leakage</a></li>
<li><a href="#structures">Structures</a></li>
</ul></li>
<li><a href="#evaluation-techniques">Evaluation Techniques</a></li>
</ul></li>
<li><a href="#modeling">Modeling</a><ul>
<li><a href="#model-selection">Model Selection</a><ul>
<li><a href="#rfe-random-forest">RFE Random Forest</a></li>
<li><a href="#rfe-gbm">RFE GBM</a></li>
<li><a href="#ffs-random-forest">FFS Random Forest</a></li>
<li><a href="#ffs-gbm">FFS GBM</a></li>
<li><a href="#quick-intro">Quick Intro</a></li>
<li><a href="#rfe-downsizing">RFE downsizing</a></li>
<li><a href="#rfe-tuning-random-forest">RFE tuning Random Forest</a></li>
<li><a href="#rfe-tuning-gbm">RFE tuning GBM</a></li>
<li><a href="#rfe-tuned-partial-dependency-plots">RFE tuned partial dependency plots</a></li>
<li><a href="#ffs-tuned-random-forest">FFS tuned Random Forest</a><ul>
<li><a href="#ffs-tuning-gbm">FFS tuning GBM</a></li>
</ul></li>
</ul></li>
<li><a href="#model-assessment">Model Assessment</a></li>
</ul></li>
<li><a href="#discussionresults">Discussion/Results</a></li>
<li><a href="#references">References</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1>Introduction</h1>
<p><strong>Introduction</strong></p>
<p>This is a workflow used to create the probabalistic spatial prediction map of stream occurence in northwest Montana. Hopefully by providing this workflow we can improve this analysis. The reason for such a dense, superfluous, and tedious workflow is that I like doing this type of analysis and also it helps me keep everything in perspective. However, it should be noted that this not the only way or is in any way intended to be a ‘cookbook’ so please take this into consideration. There are many, many ways and methods for this type analysis and a lot of it depends on the project details and objectives. Thus I want to start by highlighting some goals of this analysis and workflow, which may help summarise my rationale.</p>
<ol style="list-style-type: decimal">
<li><p>Balancing prediction performance with model interpretability while emphasising a spatial modeling framework.</p></li>
<li><p>Use feature selection techniques that will lower model processing time while reducing variance (i.e. accounting for spatial autocorrelation).<br />
</p></li>
<li><p>Optimizing climate, topographic, and remote sensing data to better predict stream occurence and understand hydrologic processess at multiple scales.</p></li>
<li><p>Test new spatial prediction techniques (forward feature selection, blockCV) with others (recursive feature elimination) so that future endeavors can be efficient while considering limitations.</p></li>
</ol>
<p><strong>Please use the tabs to navigate through this workflow process. Here is a brief summary of each tab.</strong></p>
<ul>
<li><p><strong>Accessing Data</strong> - If you want to get your hands on the data go here.</p></li>
<li><p><strong>Methods</strong> - how we got to modeling:</p>
<ul>
<li><p>Variable(s) - summary of predictor and response variable(s).<br />
</p></li>
<li><p>Pre-processing - examining predictor variables.<br />
</p></li>
<li><p>Data Splitting Guidance - determining how to split the data based on:</p>
<ul>
<li>Proportion - what’s the response’s proportion?<br />
</li>
<li>Balanced? - to resample or not?<br />
</li>
<li>Relevant Variables.</li>
<li>Prevalance - sample prevalance rate?</li>
<li>Data Leakage.</li>
<li>Dependence Strutures (i.e. spatial autocorrelation).</li>
</ul></li>
<li><p>Evaluation Techniques - feature selection and tuning/evaluation techniques</p>
<ul>
<li>Feature Selection - summary of different techniques.<br />
</li>
<li>Tuning/Evaluation - summary of different techniques.</li>
</ul></li>
</ul></li>
<li><p><strong>Modeling</strong> - the actual modeling:</p>
<ul>
<li>Model Assessment - the actual modeling with training/evaluation data.<br />
</li>
<li>Model Selection - selecting the best model while considering goals.<br />
</li>
<li>Model Performance - testing the final selected model on the test data.</li>
</ul></li>
<li><p><strong>Discussion</strong> - final thoughts on results.</p></li>
<li><p><strong>References</strong> - bibliography</p></li>
</ul>
<p>Thank you for your time and critiques as this will only make it better. Please, any comments add to the document or email [<a href="mailto:joshua.l.erickson@usda.gov" class="email">joshua.l.erickson@usda.gov</a>].</p>
</div>
<div id="accessing-data" class="section level1">
<h1>Accessing Data</h1>
<p><strong>Accessing Data</strong></p>
<p>Real quick, the csv data can be downloaded at <a href="https://drive.google.com/open?id=1Vich0zlZSmRHFM7cCLyziUmmzqN6f6Pb">csv</a>, the points downloaded at <a href="https://drive.google.com/open?id=1CvRYDRJ1xPWZ9EzdByye2I9gKSw9Ljlu">points</a>, and the tifs downloaded at <a href="https://drive.google.com/open?id=100in8JlxDCbRLTPCzQ-p9D54SQxIP37d">TIF</a>. The <strong>.tif files</strong> have been pre-processed so that projections and datums are the same and the csv data is raw so that the user can explore if they want to improve with other models or techniques (eg, cv methods, sampling, models). The points are provided to help show where the data was collected or if wanting to do a ‘ground up’ analysis as well. The point samples were collected from past and current surveys using the Montana “SMZ law” definitions, which you can find here <a href="http://dnrc.mt.gov/divisions/forestry/docs/assistance/practices/smzfullcopy.pdf">SMZ, page 3</a> and also described in <a href="#variables">Variables</a>.</p>
</div>
<div id="methods" class="section level1">
<h1>Methods</h1>
<div id="summary" class="section level2">
<h2>Summary</h2>
<p><strong>Summary</strong></p>
<p>This analysis was built off a lot of research done on the relationships between climate data, topographic indices, and hydrologic processes <span class="citation">(BEVEN and Kirkby 1979; Dobrowski et al. 2013; Hird et al. 2017; Holden and others, in prep.; Hoylman et al. 2018, 2019; Jaeger et al. 2019; Lidberg, Nilsson, and Ågren 2020; Pelletier et al. 2018; Raduła, Szymura, and Szymura 2018; Robinson et al. 2018; Sando and Blasch 2015; Sörensen, Zinko, and Seibert 2006; Stephenson 1998)</span>. The methodology, concepts, and workflow for the analysis were adapted from <span class="citation">(Friedman, Hastie, and Tibshirani 2001; James et al. 2013; Kuhn and Johnson 2013; Hird et al. 2017; Jaeger et al. 2019; Meyer et al. 2018, 2019)</span> where the authors used machine learning techniques to predict different types of response variables. Variable categories will follow three different types (e.g., digital elevation models (DEM), radar images, and optical images) that <span class="citation">Hird et al. (2017)</span> used for predicting “wet” and “dry” areas in northern Alberta, Canada. This is also a common variable selection approach as others have done <span class="citation">(Jaeger et al. 2019; Lidberg, Nilsson, and Ågren 2020; Sando and Blasch 2015)</span> within a hydrologic context.</p>
<p>Within the methods section, the goal is to emphasize the importance of accounting for spatial autocorrelation in regards to statistical learning validation techniques. It should be noted that autocorrelation in statistical learning will invalidate some of the assumptions that regression and parametric type models must have (e.g. independence) ; however, with ensemble modeling these assumptions are not neccessarily as important. But, ensemble modeling doesn’t get a free lunch and spatial autocorrelation affects the validation techniques as well as feature selection <span class="citation">(Meyer et al. 2018, 2019; Roberts et al. 2017; Valavi et al. 2018)</span>. Spatial autocorrelation affects all models in this way (e.g. validation is over-optimistic); however, it may be even more severe with ensemble modeling due to the propensity to overfit in the first place, i.e. flexible models typically have low bias and high variance which can overfit (high variance) more than a less flexible model. Also, I will bring up the concern for using <em>artificially</em> balanced data sets.</p>
<p>This has been echoed by numerous authors <span class="citation">(Kuhn and Johnson 2013; Matloff 2017; Meyer et al. 2018, 2019; Roberts et al. 2017; Valavi et al. 2018)</span>, which have provided different approaches when dealing with these concerns (e.g. validation techniques, prevalence rates). However a feature selection process is still imperative within a spatial context as <span class="citation">Meyer et al. (2018)</span>;<span class="citation">Meyer et al. (2019)</span> has shown and should be investigated as well so the model can lessen any sneaky surrogate or geo-located type variables that consistently overfit and plague spatial prediction covariates. This coupling of overfitting (e.g. validation and prevalence methods) leads to over-optimistic results and can significantly affect extrapolation and interpolation <span class="citation">(Matloff 2017; Meyer et al. 2018, 2019; Roberts et al. 2017)</span>. I will take these approaches and apply them to the data collected in northwest Montana along with some traditional methods of machine learning workflows, e.g. data splitting, leakage, etc. This may seem stringent at times but the goal is to have realistic predictions, within constrained timeframes, and while being spatially responsible. Please, if any of these approaches or methods are confusing or contradictory let me know and I would be glad to rethink my approach and respond. Thanks.</p>
</div>
<div id="variables" class="section level2">
<h2>Variables</h2>
<p><strong>Predictor Variables</strong></p>
<p>Digital elevation models (DEM) were used to generate the following: topographic wetness index (TWI), topographic position index (TPI), Deficit continuos parameter grids (CPG), and upslope accumulated area (UAA). The methods used to derive these indices followed <span class="citation">Tarboton (2013)</span> by using the command-line function in R <span class="citation">(Team 2014)</span>. A 10-m DEM USGS National Elevation Dataset <span class="citation">(Gesch et al. 2009)</span> was used to calculate upslope accumulated area (UAA) by using the d-infinity algorithm <span class="citation">(Tarboton 2013)</span>. Topographic wetness index was then calculated at 10-m resolution by using UAA and slope. Both TWI and UAA were then aggregated to 30-m resolutions with a 3x3 mean window function and resampled with nearest neighbor to retain the intricacies of the flow path direction and be able to stack with 30-m optical and radar images. Topographic position index (TPI) used the 10-m DEM USGS National Elevation Dataset and was also aggregated to 30-m resolution using a 3x3 mean window function and resampled with nearest neighbor. The PRISM CPG was taken from <span class="citation">R. Sando (2018)</span> where the variable is created by accumlating a weighted grid (average annual PRISM data (1981-2010)) and normalizing it by the UAA, which gives a ratio of precipitation and accumulated area. For the deficit CPG, the indice was derived from the 10-m flow direction grid and then aggregated to 30-m flow direction grid (to retain intricacies) from the same processeses as above <span class="citation">(Tarboton 2013)</span>, from which the grid was then weighted by a CWD grid (i.e. 30-m). This was then normalized by the UAA 30-m grid. The reason to add climatic water deficit (CWD) the observed interplay between these processes in the field.</p>
<p>Radar image collections included 10-m Sentinel-1 polarimetric Synthetic Aperture Radar (SAR) images from (‘05-15’ to ‘08-31’) for each year (2015-2019) following the methods described in <span class="citation">Hird et al. (2017)</span>: Normalized Polarization (Pol), Vertical Polarization (VV), VV Standard Deviation (VVsd). These images were collected using Google Earth Engine (GEE) <span class="citation">(Gorelick et al. 2017)</span> and code by <span class="citation">(Supplementary Material (Code S1) to: Hird et al. 2017)</span>. These were then aggregated to 30-m resolutions using a 3x3 mean window function and resampled with nearest neighbor.</p>
<p>Optical image collections included 10-m Sentinel-2 optical satellite images from August-September (‘08-01’ to ‘09-30’) for each year (2015-2019) to produce Normalized Difference Vegetation Index (NDVI) and Normalized Difference Water Index (NDWI). In addition to NDVI/NDWI, the 10-m Sentinel-2 optical satellite Blue (B2), Green (B3), Red (B4), Near Infrared (B8) images from August-September (‘08-01’ to ‘09-30’) for each year (2015-2019) were also used. These were again aggregated to 30-m resolutions using a 3x3 mean window function and resampled with nearest neighbor. Median Net Primary Productivity (NPP) <span class="citation">(Robinson et al. 2018)</span> from 1986-2018 and annual 30-m Climatic Water Deficit (CWD) <span class="citation">(Holden and others, in prep.)</span> from 1986-2016 were also used as predictors. Normalized Difference Vegetation Index (NDVI), Normalized Difference Water Index (NDWI), and median Net Primary Productivity (NPP) were collected using GEE. The 30-year Annual (July-Sept; 1986-2016) Normalized Difference Vegetation Index (NDVI), annual Climatic Water Deficit (CWD), Cold Air Drainage (CAD), Decidous (Decid), and Hydrometeorlogical Dryness Index (HDI) were taken from <span class="citation">Holden and others (in prep.)</span>.</p>
<p><strong>Now bring in all the TIFs to be used in the anlaysis and stack/visualise.</strong></p>
<pre class="r"><code>library(raster)

twi30 &lt;- raster(&quot;twi30agg.tif&quot;) #TWI

vvsd30 &lt;- raster(&quot;vvsd30agg.tif&quot;) #vertical vertical sd

vv30 &lt;- raster(&quot;vv30agg.tif&quot;) #vertical vertical mean

npol30 &lt;- raster(&quot;npol30agg.tif&quot;) #normalized polarization 

ndviAS30 &lt;- raster(&quot;ndvias30agg.tif&quot;) #NDVI aug-sept

ndwiAS30 &lt;- raster(&quot;ndwias30agg.tif&quot;) #NDWI aug-sept

accum30 &lt;- raster(&quot;accum30.tif&quot;) #UAA d-infinity aggregated from 10-m

nppMid30 &lt;- raster(&quot;nppmmid30agg.tif&quot;) #NPP median &#39;86-18&#39;

ndvi30yr &lt;- raster(&quot;ndvi30yrRS.tif&quot;) #NDVI 30 yr

deficit &lt;- raster(&quot;deficitRS.tif&quot;) # annual CWD 30 yr

wtrbdy30 &lt;- raster(&quot;wtrbdy30agg.tif&quot;) #waterbodies

tpi30 &lt;- raster(&quot;tpi30agg.tif&quot;) #TPI

HDI &lt;- raster(&quot;hdi30RS.tif&quot;) #hydrologic deficit index

CAD &lt;- raster(&quot;cad30RS.tif&quot;) #cold air drainage

decid &lt;- raster(&quot;decid30RS.tif&quot;) #deciduous

B2 &lt;- raster(&quot;B2_30agg.tif&quot;) #blue (B2)

B3 &lt;- raster(&quot;B3_30agg.tif&quot;) #green (B3)

B4 &lt;- raster(&quot;B4_30agg.tif&quot;) #red (B4)

B8 &lt;- raster(&quot;B8_30agg.tif&quot;) #Near Infrared (B8)

cpgPrecip &lt;- raster(&quot;cpg30precip.tif&quot;) #Continuous parameter grid (precipitation/PRISM).

cpgDeficit &lt;- raster(&quot;cpg30Deficit.tif&quot;) #continuous parameter grid (deficit).

topo_opt_rad30 &lt;- stack(twi30, tpi30, accum30,vv30, vvsd30, npol30, ndvi30yr, ndviAS30, ndwiAS30, nppMid30, deficit, HDI, CAD, decid, B2, B3, B4, B8, cpgPrecip, cpgDeficit)</code></pre>
<center>
<pre class="r"><code>plot(topo_opt_rad30, maxnl=32, nc = 4, legend = FALSE)</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
</center>
<p><br></p>
<p><strong>Response Variable</strong></p>
<p>The response variable was collected in a few different ways: historic and current data observations. The historic observations were collected from 1992-2004 by US Forest Service personel. They would walk drainages and identify streams by using stream classification protocols at the time (recommend <strong>copy link address</strong>) (<a href="http://dnrc.mt.gov/divisions/forestry/docs/assistance/practices/smzfullcopy.pdf">SMZ, page 3</a>, <a href="https://drive.google.com/open?id=1lX1HDkZwCiXFioaVYy4s216bunKX2d8C">Kootenai National Forest stream classifications</a>).</p>
<p>These were then evaluated using current data observations in places where these methods overlapped. Also, points were applied to the surveyed data at a 30 meter distance. In adddtion, areas with past timber sales were used as places to interpret “no stream.” Now there are a lot of assumptions with this type of data collection (observer bias, overlooked areas, streams change, etc); however, by observing these areas with the currect data observtions it was validated in an unsupervised manner (using current data, old maps, professional judgement, remote sensing, etc) with high agreement.</p>
<p>The data that overlapped showed strong similarities in the results, which made me more confident in using these data collection methods. The current data collection was performed from June-Oct in 2019. These collection methods followed the same protocol as the SMZ method. Data was collected with a Samsung Galaxy Tab A Tablet with +/- 15-30 foot accuracy. This was another reason to only use 30-meter resolution grids in the analysis as well; the accuacy at which the data was collected would have been suspect at 10 meters. The current data collected only accounted for appoximently 1500 points but was very helpful in validating the historic data as well. Below shows how the raster stack of all the predictor variables were extracted by point samples.</p>
<p><strong>Extract points from stack <code>topo_opt_rad30</code> and then combined with <code>pts</code>.</strong></p>
<pre class="r"><code>library(arcgisbinding)</code></pre>
<pre><code>## *** Please call arc.check_product() to define a desktop license.</code></pre>
<pre class="r"><code>arc.check_product()</code></pre>
<pre><code>## product: ArcGIS Pro (12.2.0.12813)
## license: Advanced
## version: 1.0.1.237</code></pre>
<pre class="r"><code>#combine point objects
pts &lt;- arc.open(&quot;D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/workingThoughProject/points_spaced30m.shp&quot;)  #points to the folder/feature
pts &lt;- arc.select(pts, c(&quot;copy_TWI_1&quot;, &quot;FID_ksank1&quot;, &quot;FID_ksan_1&quot;)) #selects the data in the folder

                        #copy_TWI_1 = stream or no stream, FID_ksan1 &amp; FID_ksan_1 are just the
                          #HUC 12 and HUC 14 polygon attributes
                            #we will use later for leave location out (LLO).

pts &lt;- arc.data2sp(pts) #now we have a spatial points data frame</code></pre>
<pre class="r"><code>library(sp)
library(rgdal)
library(rgeos)

deficit &lt;- raster(&quot;D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/workingThoughProject/deficitRS.tif&quot;) # annual CWD 30 yr

thrty.3 &lt;- mask(topo_opt_rad30, wtrbdy30, inverse = TRUE) #mask out waterbodies if you want

#Get forest service boundary
FSland &lt;- readOGR(&quot;D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/workingThoughProject/KNF_ownership.shp&quot;)
FSland &lt;- FSland[FSland$OWNER == &#39;FS&#39;,]

#Get District Boundary
DistrictBoundary &lt;- readOGR(&quot;D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/workingThoughProject/fortine_rexford_RD_Bdy.shp&quot;)

#now intersect and project
landClip &lt;- gIntersection(FSland, DistrictBoundary, byid = TRUE)

tpiCRS &lt;- crs(tpi30)

landClip &lt;- spTransform(landClip, tpiCRS)


thrty.3 &lt;- mask(thrty.3, landClip) #mask out non-Forest Service land

thrty.3 &lt;- raster::extract(thrty.3, pts) #extract the values from raster by point data

top30.opt.rad &lt;- cbind(pts, thrty.3)
top30.opt.rad &lt;- data.frame(top30.opt.rad)
plot(thrty.3)

write.csv(top30.opt.rad, file = &quot;D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/workingThoughProject/top30.opt.rad.csv&quot;)</code></pre>
</div>
<div id="pre-processing" class="section level2">
<h2>Pre-processing</h2>
<p><strong>Pre-processing</strong></p>
<p>Pre-processing data is an important step in any data anaysis. With pre-processing we will look at how the data is distrubuted (shape) and correlated. Typically within environmental science data, transformations are needed since the data normally follows a skewed pattern (i.e. lots of small events with periodic high events or vice versa) <span class="citation">(Van Bell 2011)</span>. However, we will be using tree-based <em>classification</em> methods (e.g., RandomForest, Gradient Boost) for the predictive model; thus, transformations will not be as important because tree-based <em>classification</em> models are not sensitive to scale or distributions (i.e., metrics used for partitioning nodes don’t involve regression-type statistics (RSE) instead splits feature space(s) by purity methods, e.g. Gini index, cross entropy). However, just like any statistical learning practice, context matters. Thus you may want to transform your data, even with a tree-based <em>classification</em> method. That being said, I still think it is prudent to look at the data descriptively before we jump in regardless of model type.</p>
<p>To start we can look at the shape of the data and how it’s plotted against other variables. This involves looking at histograms and scatter plots of the data visually. Since we have 19 predictors this will be pretty difficult to look at scatter plots so we will just look at histograms (sidebar - I’ve look scatter plots individually and there are some interesting trends but mostly uncorrelated). Let’s bring in the data we just created in the Variables section and start exploring.</p>
<pre class="r"><code>top30.opt.rad &lt;- read.csv(&quot;D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/workingThoughProject/top30.opt.rad.csv&quot;, header = TRUE)[-1]

data &lt;- top30.opt.rad #change for ease
data &lt;- data[,-26] #take out irrelavant index
#change names
names(data)[2] &lt;- &quot;HUC12&quot;
names(data)[3] &lt;- &quot;HUC14&quot;
names(data)[1] &lt;- &quot;stream&quot;
data$stream &lt;- factor(data$stream)
data &lt;- na.omit(data)
 # write csv

write.csv(data, file = &quot;D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/workingThoughProject/trainDat.csv&quot;)</code></pre>
<p><br></p>
<p>Now lets look at the histograms of the predictor variables.
<br></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><br>
From the graph above it looks like there are some outliers in the data set. However, the tree-based models we will use are not so sensitive to outliers; again, it should be noted that you don’t neccessarily want to remove outliers so hastily and understanding of the data is key. No free lunch! On the other hand, correlation statistics can be sensitive to outliers and tree-based <em>classification</em> models can have a hard time with correlated variables. So we will want to explore any noticeable outliers before doing any correlation estimates. I’ll just use a simple outlier detection by looking at the histograms. From the histogram there were three graphs that looked suspect: npol30agg, hdi30RS, and accum30 so we will look at those.</p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-7-1.png" width="672" style="display: block; margin: auto;" />
<br>
Both <code>npol30agg</code> and <code>accum30</code> look like they have a couple of significant outliers. Thus leaving <code>accum30</code> alone will be fine (since an UAA that large is likely) but the npol30agg needs to be between -1 and 1, theorhetically. This is totally appropriate because it doesn’t affect the ‘true’ distribution of the data. For example, if we took outliers out that were theorhetically possible, then the test data would have a peak at the ‘new’ distribution, i.e. data leakage. We’ll talk abou data leakage later but remember to not hastily take out data without taking leakage into consideration.</p>
<pre class="r"><code>data &lt;- data[!data$npol30agg &lt; -1,]
data &lt;- data[!data$npol30agg &gt; 1,]</code></pre>
<p><br>
Now look at the new boxplot and histogram for <code>npol30agg</code>, which looks much better.</p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-9-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>The next step is to look for correlated data. Correlations in the data will give us an idea of some redundant data (e.g. collinearity). We can investigate correlation visually through the function <code>corrplot</code> and look for any colinearity with the predictors or see if there is any clustering <code>hclust</code>. These type of plots are very useful when the amount of predictors is above 20 (<code>pairs.plot</code> gets overwhelmed) and gives a quick view of what’s going on. After visualising, we can take a deeper look and search the data frame for correlation using a certain threshold (e.g., 90%). This is possible by <code>caret</code>’s function called <code>findCorrelation</code>. This is the cutoff threshold that <span class="citation">Hird et al. (2017)</span> and <span class="citation">Lidberg, Nilsson, and Ågren (2020)</span> used but it might be worth exploring some lower cutoffs. I tried 60% to start off and got eight variables.</p>
<pre class="r"><code>library(corrplot)</code></pre>
<pre><code>## corrplot 0.84 loaded</code></pre>
<pre class="r"><code>library(caret)
correlations &lt;- cor(data[,-c(1,2,3,24,25)]) #remove response,coords and HUCs
corrplot(correlations, order = &quot;hclust&quot;)</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-10-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>highCorr &lt;- findCorrelation(correlations, cutoff = 0.6)
highCorr</code></pre>
<pre><code>## [1] 16 15 20 11 12 18  8  4</code></pre>
<p>There are eight variables recommended to be taken out. Let’s see what they are.</p>
<pre class="r"><code>colnames(correlations)[c(16,15,20,11,12,18,8,4)]</code></pre>
<pre><code>## [1] &quot;B3_30agg&quot;     &quot;B2_30agg&quot;     &quot;cpg30Deficit&quot; &quot;deficitRS&quot;    &quot;hdi30RS&quot;      &quot;B8_30agg&quot;     &quot;ndvias30agg&quot;  &quot;vv30agg&quot;</code></pre>
<p>There are a few ways we can approach this; take them out, do some sort of dimension reduction or raise the threshold bar. We can check the threshold by moving it up to let’s say 75%, which is a little more of a conservative value.</p>
<pre class="r"><code>highCorr2 &lt;- findCorrelation(correlations, cutoff = 0.75)
highCorr2</code></pre>
<pre><code>## [1] 16 15 20 11 18  8</code></pre>
<pre class="r"><code>colnames(correlations)[c(16,15,20,11,18,8)]</code></pre>
<pre><code>## [1] &quot;B3_30agg&quot;     &quot;B2_30agg&quot;     &quot;cpg30Deficit&quot; &quot;deficitRS&quot;    &quot;B8_30agg&quot;     &quot;ndvias30agg&quot;</code></pre>
<p>With this threshold of 75% we ended up only dropping <code>hdi30RS</code> and <code>vv30agg</code> in the list. The remaining variables make sense why they would be correlated; <code>cpg30Deficit</code> and <code>deficitRS</code> both have CWD, the B’s are all reflectances, and <code>ndvias30agg</code> is highly correlated with its counterpart <code>ndwias30agg</code> and B8. By keeping these variables in the analysis it is likely to be couterproductive unless some sort of dimension reduction is applied. The disadvantage of dimension reduction is that you lose interprebility with these variables and you also might miss the mark on causation. Advantages include using decorrelated variables that normally would have been taken out of the model and reducing dimensions in statistical learning is always a worthwhile consideration (e.g. ‘curse of dimensionality’). It’s a tricky decision.</p>
<p>There is no clearcut way of doing this, so suggestions are welcomed. Again, no free lunch!. Thus I decided to drop <code>ndvias30agg</code> and here’s why; I don’t mind dropping <code>ndvias30agg</code> because we have <code>ndwias30agg</code> and we also have a long-term NDVI <code>ndvi30yrRS</code>as well. Therefore, by dropping this variable we remove some redundancy and keep some interprebility which I think is a good trade-off in this analysis. However, I decided to do a principal component analysis (PCA) with the reflectance band variables and the two CWD variables. One could probably argue to just take away one of the deficit variables but for some reason my confirmation bias want to keep them. So bear with me on the rationale below as it would be just as easy to take one out.</p>
<p>The reflectances interprebility to me seems hard pressed in the first place so the trade-off comes down to possible model performance over interprebility. Therefore, I would rather keep them in the analysis with the downfall of losing some interprebility at the expense of possibly having better model performance. It’s a little tricky with the CWD variables, we would want some interprebility from them but we are going to have to lose that with a reduction, again trade-offs. I think that they are both below a 90% threshold, so leaving them wouldn’t be the worst thing but we also have <code>hdi30RS</code> as a predictor, which is a recently studied, validated, and published model for water and energy feedbacks. Therefore reducing the dimension of <code>deficitRS</code> and <code>cpg30Deficit</code> at the expense of interprebility isn’t as big of loss. However, if we didn’t have <code>hdi30RS</code> I would probably consider dropping one.</p>
<p>Now we want to make sure that we don’t leak any data in the process (i.e. data leakage) as well so we will need to process the components during cross-validation. What this means is that you don’t want to preprocess your PCA data on both test and training data; thus, a PCA prior to cross-validation is a concern and should be avoided. The PCA will be done within the cross-valdition procedure in the <code>caret</code> function using a <code>recipe</code>, which allows us to be specific with variables that we want to preProcess. So lets take out the predictor variable <code>ndvias30agg</code> that we determined to be redundant and collinear and wait to do anything with the PCA until later during the modeling.</p>
<p>*Update I’m dropping <code>cpg30Deficit</code>. In short, not worth it. Will be exploring in the future though.</p>
<pre class="r"><code>data &lt;- data[, -which(names(data) %in% c(&quot;ndvias30agg&quot;, &quot;cpg30Deficit&quot;))]</code></pre>
<p>Now we can move on to the spatial pre-proccesing section.</p>
<p><strong>Spatial Pre-proccessing</strong></p>
<p>Pre-proccessing the spatial data is a very important process (e.g., projections, resolution, etc) and can be troublesome if not done correctly or overlooked. The predictor variables mentioned in the <em>Variables</em> section used the following pre-processing techniques below. These data started at 10m resolution (e.g., tpi, twi, uaa, ndvi/ndwi Aug-Sept, vv, vv sd, npol) and were then aggregated by a mean function (3x3 window) and resampled by nearest neighbor to retain inherent values from the aggregation. The aggregated and resampled data were then rasterized and saved as a tif. Below is the process to get each TIF from 10m to 30m resolution. Resampling was done to make sure any changes in the aggregation would be rectified, if any. This pre-processing was also done to all the 30m spatial data that wasn’t 10m to retain correct CRS.</p>
<pre class="r"><code>tpi30 &lt;- aggregate(tpi, fact = 3, fun = mean) #aggregate from 10-m TPI
tpi30 &lt;- resample(tpi30, ndvi30yr, method = &quot;ngb&quot;)
writeRaster(tpi30, filename = &quot;tpi30agg.tif&quot;, overwrite = TRUE)
tpi30 &lt;- raster(&quot;tpi30agg.tif&quot;)</code></pre>
<p>To check the correct CRS, resolution, extent, and dimensions for all the variables I used the process below. However, I will only show the first couple of grids. The data is already pre-processed so i’ll bring in a differing grid to show the process.</p>
<pre class="r"><code>library(raster)
dem30test &lt;- raster(&quot;D:/Rcodes/FDir/dem30test.tif&quot;)
dem30test</code></pre>
<pre><code>## class      : RasterLayer 
## dimensions : 2236, 2411, 5390996  (nrow, ncol, ncell)
## resolution : 30, 30  (x, y)
## extent     : 150040.6, 222370.6, 507396.9, 574476.9  (xmin, xmax, ymin, ymax)
## crs        : +proj=aea +lat_1=46 +lat_2=48 +lat_0=44 +lon_0=-109.5 +x_0=600000 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0 
## source     : D:/Rcodes/FDir/dem30test.tif 
## names      : dem30test 
## values     : 221, 2517  (min, max)</code></pre>
<pre class="r"><code>tpi30</code></pre>
<pre><code>## class      : RasterLayer 
## dimensions : 2237, 2411, 5393407  (nrow, ncol, ncell)
## resolution : 30, 30  (x, y)
## extent     : 150035.8, 222365.8, 507390, 574500  (xmin, xmax, ymin, ymax)
## crs        : +proj=aea +lat_1=46 +lat_2=48 +lat_0=44 +lon_0=-109.5 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs 
## source     : D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_workflow/tpi30agg.tif 
## names      : tpi30agg 
## values     : -24.60378, 35.87562  (min, max)</code></pre>
<p>Now project <code>dem30test</code> to <code>tpi30</code> using the function <code>projectRaster</code>.</p>
<pre class="r"><code>tpiCRS &lt;- crs(tpi30)

dem30proj &lt;- projectRaster(dem30test, tpi30, res = 30, crs = tpiCRS, method = &quot;ngb&quot;)

dem30proj &lt;- raster::resample(dem30proj, tpi30, method = &quot;ngb&quot;)

writeRaster(dem30proj, &quot;D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/workingThoughProject/dem30proj.tif&quot;, overwrite = TRUE)</code></pre>
<p>Now the data is in the same projection, ellipsoid, datum, extent, and dimension. Do this for all the grids in the data set. The reason for albers conic equal area (<code>+proj=aea</code>) was that the DEM was in this projection and so the flow accumulation, twi, tpi were built off of these. In the end I don’t think it matters too much since the sample space is relatively local. But any comments would be appreciated.</p>
<pre class="r"><code>dem30proj</code></pre>
<pre><code>## class      : RasterLayer 
## dimensions : 2237, 2411, 5393407  (nrow, ncol, ncell)
## resolution : 30, 30  (x, y)
## extent     : 150035.8, 222365.8, 507390, 574500  (xmin, xmax, ymin, ymax)
## crs        : +proj=aea +lat_1=46 +lat_2=48 +lat_0=44 +lon_0=-109.5 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs 
## source     : memory
## names      : dem30test 
## values     : 221, 2517  (min, max)</code></pre>
<pre class="r"><code>tpi30</code></pre>
<pre><code>## class      : RasterLayer 
## dimensions : 2237, 2411, 5393407  (nrow, ncol, ncell)
## resolution : 30, 30  (x, y)
## extent     : 150035.8, 222365.8, 507390, 574500  (xmin, xmax, ymin, ymax)
## crs        : +proj=aea +lat_1=46 +lat_2=48 +lat_0=44 +lon_0=-109.5 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs 
## source     : D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/Final_workflow/tpi30agg.tif 
## names      : tpi30agg 
## values     : -24.60378, 35.87562  (min, max)</code></pre>
<p>Heres how I derived the CPG grid for deficit below.</p>
<pre class="r"><code>tpi &lt;- raster(&quot;tpi.tif&quot;) #bring in tpi for cropping

z=raster(&quot;D:/Rcodes/FDir/dem10m.tif&quot;) #bring in 10-m DEM

c &lt;- crop(z,tpi) #crop to tpi

writeRaster(c, &quot;croppedDEM10.tif&quot;)

c &lt;- resample(z, tpi, method = &quot;ngb&quot;) #resample with tpi
c &lt;- mask(c,tpi) #mask with tpi

writeRaster(c, &quot;dem10m.tif&quot;, overwrite = TRUE)



#####This is the command-line Tarboton TauDEM process####

# Pitremove
system(&quot;mpiexec -n 8 pitremove -z dem10m.tif -fel dem10fel.tif&quot;)
fel=raster(&quot;dem10fel.tif&quot;)
plot(fel)
zoom(fel)

# DInf flow directions
system(&quot;mpiexec -n 8 DinfFlowdir -ang dem10ang.tif -slp dem10slp.tif -fel dem10fel.tif -nc&quot;,show.output.on.console=F,invisible=F)

dem10ang &lt;- raster(&quot;dem10ang.tif&quot;) 

defdis &lt;- disaggregate(deficit, fact=3) #downscale deficit 30-m raster

s &lt;- resample(defdis, dem10ang, method = &quot;ngb&quot;) #then resample

s &lt;- mask(s, dem10ang) #mask to get it aligned with the angle raster

s[is.na(s[])] &lt;- 0 #now set NA&#39;s equal to zero so TauDEM deoesn&#39;t fuss

writeRaster(s, &quot;defdis.tif&quot;, overwrite = TRUE)

# Dinf contributing area

#weighted with deficit

system(&quot;mpiexec -n 8 AreaDinf -ang dem10ang.tif -sca DEF10sca.tif -wg defdis.tif -nc&quot;)

#normal UAA
system(&quot;mpiexec -n 8 AreaDinf -ang dem10ang.tif -sca DEM10sca.tif -nc&quot;)

#now do the math
cpg30Deficit &lt;- overlay(DEF10sca, DEM10sca, fun = function(r1,r2){return(r1/r2)})

#then aggregate to 30-m to retain finer scale flow patterns

cpg30Deficit &lt;- aggregate(cpg30Deficit, fact=3, fun=mean)

#then get it lined up with the other rasters

cpg30Deficit &lt;- projectRaster(cpg30Deficit, tpi30, res = 30, crs = tpiCRS, method = &quot;ngb&quot;)

cpg30Deficit &lt;- raster::resample(cpg30Deficit, tpi30, method = &quot;ngb&quot;)

writeRaster(cpg30Deficit, &quot;cpg30Deficit.tif&quot;, overwrite = TRUE)</code></pre>
</div>
<div id="splitting-data" class="section level2">
<h2>Splitting Data</h2>
<div id="guidance" class="section level3">
<h3>Guidance</h3>
<p><strong>Data Splitting Guidance</strong></p>
<p>Data splitting is a crucial part of the modeling workflow because it involves how the data gets trained/tuned and tested, which ultimately affects performance (i.e. interpolation and extrapolation) <span class="citation">(Kuhn and Johnson 2013)</span>. This section will have a lot of details that at times will seem tedius, redundant, stringent and nuanced. My appologies. However, I think the cost benefit of following these approaches will only help correct for overfitting and insufficient model interpretations. That is to say, the cost is low to explore these details while the benefit is high when compared to the complement, e.g. plug and chug.</p>
<p>Thus different data splitting approaches can influence the risk of overfitting <span class="citation">(Friedman, Hastie, and Tibshirani 2001; Matloff 2017; James et al. 2013; Kuhn and Johnson 2013)</span> and data leakage <span class="citation">(Kaufman et al. 2012)</span>; especially within a spatial context <span class="citation">(Bahn and McGill 2013; Elith, Leathwick, and Hastie 2008; Ives and Zhu 2006; Meyer et al. 2018, 2019; Roberts et al. 2017)</span>. One way to pursue these splitting approaches while avoiding pitfalls can be through how you split your data and/or interpret and choose your data (predictors) i.e. <em>Data Splitting Guidance</em>. This is one of the sections in the workflow where I got into some really deep rabbit holes and went back and forth on different strategies. That be said, perpspective or comments in this section would be much appreciated. The <strong>actual</strong> data splitting will be done in the ‘Modeling’ section and think of this as the rationale of how we got there. Thus I will take these steps below, which is a blend of <span class="citation">Kuhn and Johnson (2013)</span>, <span class="citation">Matloff (2017)</span>, <span class="citation">Meyer et al. (2019)</span>, <span class="citation">Roberts et al. (2017)</span> and <span class="citation">Valavi et al. (2018)</span> as ways to approach structured and/or imbalanced/rare data in a statistical learning context. Below is an outline of this section.</p>
<ul>
<li>Proportion of response.</li>
<li>To balance or not to balance.</li>
<li>Cause and effect of variables to response.</li>
<li>Prevalance. Who cares…</li>
<li>Minimize data leakage.</li>
<li>Assess dependence structures in data</li>
</ul>
</div>
<div id="proportion" class="section level3">
<h3>Proportion</h3>
<p><strong>Proportion</strong></p>
<p>I will start off by looking at the proportion of classes (“stream”, “no stream”) in the response variable. Zero (0) = “no stream” and one (1) = “stream”. I used the <code>arcgisbinding</code> package but of course other methods can be used. I like interfacing between ArcGIS and R because of the visuals, however packages like <code>mapview</code> are just as good for exploring visually and are free! As always, you can bring in the <code>points_spaced30m.shp</code> with the <code>sf</code> package.</p>
<pre class="r"><code>barplot(prop.table(table(pts$copy_TWI_1)),
        main = &quot;Proportion of stream occurence&quot;, 
        names.arg = c(&quot;No Stream&quot;, &quot;Stream&quot;), ylab = &quot;Proportion %&quot;) </code></pre>
<img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-19-1.png" width="70%" style="display: block; margin: auto;" />
<table>
<caption>
<span id="tab:unnamed-chunk-20">Table 1: </span>Count
</caption>
<thead>
<tr>
<th style="text-align:left;">
Stream
</th>
<th style="text-align:right;">
Freq
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
0
</td>
<td style="text-align:right;">
5661
</td>
</tr>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
6910
</td>
</tr>
<tr>
<td style="text-align:left;">
Sum
</td>
<td style="text-align:right;">
12571
</td>
</tr>
</tbody>
</table>
<table>
<caption>
<span id="tab:unnamed-chunk-20">Table 1: </span>Proportion
</caption>
<thead>
<tr>
<th style="text-align:left;">
Stream
</th>
<th style="text-align:right;">
Freq
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
0
</td>
<td style="text-align:right;">
0.45
</td>
</tr>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
0.55
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>The proportion and count of the response brings up some important questions. Should we downsample or upsample or leave it how it is? How much data should we use for evaluating performance e.g., training/tuning? What is the prevalence of stream occurence in the first place (prior)? These are all important questions and I hope to acknowledge them below but looking for some additional insights into this process as well.</p>
</div>
<div id="balanced" class="section level3">
<h3>Balanced?</h3>
<p><strong>Balanced?</strong></p>
<p>Within environmental classification models there can be a natural imbalance when collecting the data randomly, i.e. target class is typically rare. Downsampling or upsampling can correct for this class imbalance when training the data, which means the model doesn’t have to deal with this imbalance while training. However, it’s not that imbalanced data sets are a problem and must be balanced but it ultimately depends on the goals and objectives of the project, i.e. sometimes the minority group is so rare (&lt;1%) that balancing might help spot trends in prediction which can help with interpretation and selection. We will explore the “to balance or not to balance?” in the paragraphs below.</p>
<p>Typically you want to sample randomly so that you end up with a unbiased sampling distribution in the first place. If a random sampling method was pursued, in our case, results would most likely be 1-10% proportion for the minority class (<em>stream occurrence</em>) and the rest going to <em>no occurrence</em> (&gt;90%), depending on location. This means having really really low samples of our response target class, i.e. stream occurence! As you saw in the proportion section we have a higher proportion of streams occuring compared to streams not occurring, which as you can imagine is not a realistic distribution. This artificial distribution between classes highlights the observation bias in our sampling scheme and points to some flaws we might run into when we model.</p>
<p>Consequently, collecting data this way (e.g. observation bias) lends itself to a balanced data set. This is not a bad thing but should be noted and always in the back of the head for the modeler, i.e. we have a lot of <em>“stream occuring”</em> samples. Therefore, leaving the sample proportion the way it is could potentially be adequate for our analysis. However, there are conflicting interpretations and suggetions for dealing with these imbalances <span class="citation">(Kuhn and Johnson 2013; Matloff 2017)</span>. Therefore, just remember it’s biased towards the minority in the training context and it might be advantageous to train on <em>natural</em> prevalence distributions between classes.</p>
<p>It does bring up a good point though e.g. prevalence, how should the test data be tested or used? This is where the importance of spatial feature and validation techniques are necessary because the data are collections of non idependent realizations in the sampling process and also have a serious imbalance (if collected randomly). Thus spatial autocorrelation is present in our sampling scheme along with a ‘rare-ish’ prevalance rate. I want you to just keep this topic in mind. That is to say, minority group is <em>stream</em>, majority group is <em>no stream</em> and what’s the actual rate of prevalance (it’s definitely not 50/50!) nested within a spatial context. This might give some insight into how to split and evaluate the data so that we can achieve optimal results while accounting for these conditions!</p>
<p>Ultimately we want a model that can perform well but also be aware of what the <em>natural</em> conditions are so that we can make more informed decisions under uncertainty. Testing these two approaches (balanced vs. unbalanced/natural) will be an interesting topic and study as others have alluded to its concern <span class="citation">(Kuhn and Johnson 2013; Matloff 2017; Roberts et al. 2017)</span>.</p>
</div>
<div id="cause-and-effect" class="section level3">
<h3>Cause and effect</h3>
<p><strong>Cause and effect</strong></p>
<p>One way to start anticipating the data splitting process is to go over predictor variables and examine whether or not these variables would be appropriate predictor variables in the first place. This is really important if the goal is extrapolation because irrelevant variables can fail big time when going beyond your ‘small world’ model. Surrogate variables are common traps to avoid with any model and should be met with skeptisism (i.e. spurious correlation). Typical surrogate variables in environmental sciences include but are not limited to: elevation, coordinates, slope, ids, similar ratios, dummy variables, etc <span class="citation">(Roberts et al. 2017; Meyer et al. 2018, 2019; Van Bell 2011)</span>. The goal is to avoid these type of variables in the first place and/or transform appropriately; therfore, a thourough evaluation of your variables is a good idea. However there are many times where the predictor variables exceed such a value that any sane person would not dare to approach a one-by-one strategy. Hence, spatial feature selection and validation techniques <span class="citation">(Roberts et al. 2017; Meyer et al. 2018, 2019; Valavi et al. 2018)</span> have been provided by these authors to lessen the strain and time of the modeller within these structured dependance domains. These feature and validation techniques are an option to search your variables if size of <em>p</em> is too demanding but it’s always good to give an adequate examination if not (this is especially true if you’re out of your domain e.g. hydrologist determining wildlife predictors).</p>
<p>In our example there are 16 predictors that were specifically chosen from hydrologically relevant papers <span class="citation">(Hird et al. 2017; Hoylman et al. 2019; Jaeger et al. 2019; Lidberg, Nilsson, and Ågren 2020; Sando and Blasch 2015)</span> where the response (water) and predictors (remote sensing data) were used to optimize prediction. Three other variables: <code>decid</code>, <code>cad</code>, and <code>deficitCPG</code> are new to modeling hydrologic processes, from what I could gather. Of these three variables, the one variable that I could see being spurious is <code>deficitCPG</code>. This variable will be one I keep my eye on through the modeling process. On the other hand, all the other variables we’ll be using are considered relevant within a hydrological context and appropriate for cause and effect relationships, especially when considering critical zone processes <span class="citation">(Pelletier et al. 2018)</span>. One concern that was brought up though was whether or not Upslope Accumulated Area (UAA) was a surrogate variable or not? This was the case for the <span class="citation">Jaeger et al. (2019)</span> paper where the authors decided not to include UAA exactly for this reason. <span class="citation">Jaeger et al. (2019)</span> objectives were different than ours in the sense that they were concerned with stream permanance but not with stream occurrence. There’s a subtle difference here and to us it makes sense to include UAA. However, this is a good example of where data that’s not relevant or causal to sneak in.</p>
<p>Hence we’ll leave the predictors we already selected. It would be challenging to test the UAA surrogate hypothesis. The only other option would be to see if the foward feature selection picks UAA or not? The hypothesis is that if UAA is ‘geo-located/surrogate’ variable then predicting outside its dependance structure space (i.e. range) on the the response would by theory result in the forward feature selection from <span class="citation">Meyer et al. (2018)</span> to not pick it as a variable or it’s highly unlikely to pick it. This is due to these type-variables propensity to under-and-over fit, i.e. very high error with model performance metrics, see <span class="citation">Meyer et al. (2018)</span>. Therfore, this will be a topic to address in the anlaysis results/discussion section. If there are other ways to possibly test for this particular issue please let me know.</p>
</div>
<div id="prevalance" class="section level3">
<h3>Prevalance</h3>
<p><strong>Prevalance</strong></p>
<p>Please read this with the caveat that it’s a interesting topic but is very nuanced and heavy on theory. I can sum it up pretty quick; do we use <em>natural</em> prevalence rates or not? To balance these two methods I propose using minority prevalance rates <span class="math inline">\((0.05, 0.10, \dots, 0.50)\)</span> to test the final models on and using minority prevalence to compare against a balanced data set. For example, after tuning the models we will have a good idea of what the models perfomance will be over multiple tuning parameters (this is for the balanced data set). Then we can use the final test data to compare our tuned models using the different minority thresholds, e.g. let’s say we have 2000 in the final test set; then for each model, <span class="math inline">\(2000*(0.05, 0.10, \dots, 0.50) = (100,200, \dots , 1000)\)</span> we will have a <em>minority</em> amount we can test the model on. This seems like a nice idea but to acutally test it we would need to model a seperate set of data with <em>natural</em> prevalence rates.</p>
<p>The reason why this is so important is that if you train your model with a <em>artificial</em> proportion, then your model will assume a 50/50 split in the <em>real world</em> as your <em>un</em>conditional probability. In our case, this could lead to overfitting because when the model starts to predict (unknown locations) the model assumes a <em>un</em>conditional probability of 50%, which effects the feature splitting (e.g. mtry or root node and Gini Index and loss function in our case) and the logistic function in GBM, i.e. GBM uses pseudo residuals to slowly grow learners, however it starts with an initial probability and that’s where we run into a problem because it assumes that both classes are 50/50 or whatever the class proportion is (55% in our case), which is not correct and ultimately affects the residuals. Again, this is very nuanced and the level to which this will affect the model in our case is unknown but it is also the reason we want to test for it. Below shows a rfe model with 55% “stream” and 10% “stream”. Notice the big difference between the spec/sens relationship.</p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-21-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p>So like I said above, one way is to use all the data we have (balanced data) and then test on <em>natural</em> prevalence rates with the ‘vaulted’ test set and the other way is to implement the prevalence rate within the training data and the final ‘vaulted’ test set. The goal is to see how much of a difference these two techniques are and how we can move foward with modeling this type of spatial data, i.e. data that is spatial and target class is rare so that we can have suffient models. Please let me know what your thoughts are as this is very subtle. Now if you want to read below it basically goes into some very nuanced stuff. Read on if you like. Below could be a way to visualize the compromise, i.e. train on 50/50 proportion and assess on different prevalence rates.</p>
<pre><code>## `geom_smooth()` using formula &#39;y ~ x&#39;</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-22-1.png" width="672" style="display: block; margin: auto;" /></p>
<p>When splitting the data a critical part becomes how will you test the data, or how much will you leave out for testing? (side bar - there are a lot of nuances in model selection and validation techniques, all have their place and reasons and there is not a perfect ‘one-size-fits-all’ approach, but leaving a validation set out for a sanity check is common practice regardless of training techniques). The test set should be sampled to be more representitive of the response frequencies <span class="citation">(Kuhn and Johnson 2013)</span> if an inherent imbalance occurs naturally (these can change and are dynamic in some cases). So, if you’re going to validate on a hold-out test set be sure the test set matches the inherent prevalance rate (most of the time it’s unknown and cannot infer…). This becomes tricky again since we are dealing with spatial data (eg., climate, geology, landtype). This seems to be very nuanced and pedantic. I am aware.</p>
<p>However, this still doesn’t get at the issue that others <span class="citation">Kuhn and Johnson (2013)</span> and <span class="citation">Roberts et al. (2017)</span> have brought to the users attention, i.e. testing model with a representitive prevalance rate. This may seem too stringent and unrealistic for most circumstances but in our case we have a sufficient amount of data and we can calculate the prevalance rate in different spatial structures. Thus we will use this methodology for testing the final data along side the traditional approach of using the stratified random sample that was produced when splitting, i.e. your test set is partioned to have a <span class="math inline">\(\approx\)</span> 50/50 split between the binary response proportions. Therefore we will move on with calculated the prevalance rates below.</p>
<p>I decided to use the climatic water deficit (CWD) tertile method similar to <span class="citation">Hoylman et al. (2019)</span> as a way to break up the sample space into water-limiting and energy-limiting geographic zones. The advatages of using CWD as geographic partitioning is that it takes into account numerous biophysical processes, albeit modeled. Numerous papers have shown the interplay between these processes and the advantage it has over traditional geographic partitioning, e.g. elevation, precipitation, vegetation type, etc <span class="citation">(Hoylman et al. 2018, 2019; Lutz, Van Wagtendonk, and Franklin 2010; Stephenson 1998)</span>. From these tertiles we can calculate prior distributions of stream prevalence from watersheds that we have copious amounts of data on, which will help us when we test the data on the final model. These distristributions will then get transferred to a global (whole sample space) and three local (tertiles) geogrpahical zones from which the inherent prevalance rate can be used to test the final selected model on; allowing us to compare and contrast statistics (e.g., Kappa, ROC, etc). This will hopefully give us a more realistic model assessment result to be used when comparing with controls (eg., NHD, PROSPER). However, you can only imagine how low these rates would be!</p>
<p>That being said, just doing a few distributions one can see that even a low deficit zone (energy limiting) has only a 10% prevalance rate. That means that if we left out 3,000 points to test the final model we would then only have 300 points of “stream” to acutally test the model performance metrics on. So, to balance this problem comes an easy solution; just test both rates (e.g., 50/50 and ‘natural’). This is easy because the test set is locked in a ‘vault’ and not touched until the final model assessment from which we can use either method (training proportion vs ‘natural’ prevalance) on. No harm, no foul. Just keeping your sanity through all this mess of nuances and tedious minutue is a struggle. Hence I will derive a very basic prior using some approximation methods (e.g. division :).</p>
<p>First we will split the data into tertiles of CWD. We will clip the data to US Forest Service ground because that’s where we want to predict and where our data is from.</p>
<p>Calculate the tertile of <code>deficit</code> and use these values to reclassify.</p>
<pre class="r"><code>#now calculate the tertile and reclassify

quantile(defTert, probs = c(.33,.66))</code></pre>
<pre><code>## 33% 66% 
## 243 313</code></pre>
<pre class="r"><code>defTertRC &lt;- reclassify(defTert, c(0,243,1, 243,313,2, 313,Inf,3))</code></pre>
<p>Now Plot</p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-25-1.png" width="40%" /><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-25-2.png" width="40%" />
<br></p>
<p>Now we have a raster broken into tertiles of CWD. However, we want to be able to sort these characteristics by watershed beacause that’s the spatial structure our response is most relavant to, i.e. streams are cumulative to basin architexture and HUCs are perfect fit. So, we will use the 12th HUC watershed as a mediator for CWD and then reclassifing per HUC12 by taking the mode of <code>deficit</code>. The reason to use HUC12 is that it limits the amount of spatial autocorrelation when compiling zonal summary statistics, i.e. it’s more representative of the overarching CWD and not the discrete CWD value.</p>
<pre class="r"><code>library(raster)
library(sf)
library(exactextractr)

HUC12 &lt;- readOGR(&quot;D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/workingThoughProject/ksank12thclip.shp&quot;)

HUC12sf &lt;- st_as_sf(HUC12)
HUC12sf$mean_Def &lt;- exactextractr::exact_extract(deficit, HUC12sf, &#39;mean&#39;)

#or gather other info
HUC12sf[,c(&quot;modeDEF&quot;, &quot;countDef&quot;)] &lt;- exact_extract(deficit, HUC12sf, c(&#39;mode&#39;, &#39;count&#39;))</code></pre>
<p><br>
Now plot</p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-27-1.png" width="50%" /><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-27-2.png" width="50%" /><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-27-3.png" width="50%" />
<br></p>
<p>I still want to use the mode after looking at the plots as it represents the processes of CWD more clearly than the mean. I think this can be seen in the histograms below. The mean tends to smooth out the HUC12 watersheds when in fact there are more “drier” type landscapes in the valley, i.e. valley may have a few larger streams/rivers carving through but adjacent hillslope processes are most likely drier and this rationale gets smoothed with the mean.</p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-28-1.png" width="50%" /><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-28-2.png" width="50%" />
<br><br />
<br>
Now I’ll select HUC12’s that we have copious amounts of data on where we can then extract a distribution from. Visualize in ArcGIS to get the names.</p>
<p><br>
<br></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-29-1.png" width="50%" style="display: block; margin: auto;" />
<br>
<br>
From here we can sample from these different HUC12s and come up with a basic and I mean basic idea of stream prevalance. Remember, this is just to help us test the final model during assessment. Very tedious, possibly stringent, and most likely a little off; but, will be more representitive of a <em>natural</em> stream prevalance rate. For these type analysis it might not be neccessary (i.e. minimal difference) but others <span class="citation">(Kuhn and Johnson 2013; Roberts et al. 2017)</span> have alluded to the importance and thus we will see how it does with our data. It’s important to note the differences between detecting certain responses and the wiggle room that’s acceptible. For example, cancer and stream detection are extremely different; hence it’s probably worth the trouble of finding a prevalance rate for cancer detection than streams but this is up to the goals and objectives of the project in the first. All we are doing is exploring this option to get a glimpse. My personal bias is that it matters and will give a more realistic final model assessment; however, that’s my bias so I account for the confirmation bias in the results/discussion section, i.e. take a hard look. So, please take these concepts into consideration when reviewing this section in such that the main goal is hypothesis testing not hypothesis generation. Hopefully this will give a glimse into some of the nuanced debates about testing spatial data on prior distributions. Onward!</p>
<p>Now we need to rasterize the polygons and points so we can sample.</p>
<pre class="r"><code>#polygon to raster
deezy &lt;- as_Spatial(densityHUCs)
deezy &lt;- spTransform(deezy, tpiCRS)
densHUC12rast &lt;- rasterize(deezy, deficit, name=&quot;values&quot;)

#now points to raster

ptsRast &lt;- rasterize(pts, deficit , name=&quot;values&quot;)

#now select only raster values equal to 1
filter_pts &lt;- ptsRast$copy_TWI_1 %in% 1</code></pre>
<p><br></p>
<p>After a quick view it was apparant that the point method was not going to work. Thus I pivoted and used an accumulation threshold to be sampled as the global density. The reason for doing this is it’s a balance between the results being 0 for a dry area and 5% for wetter areas. I felt this was an appropriate compromise. Therefore, we will only use a <em>global</em> prevalance rate for the final model assessment against the 50/50.</p>
<pre class="r"><code>#then extract from the polygons
accumThresh &lt;- reclassify(accum30, c(-Inf, 10000, 1, 10000, Inf, 2))
rHucs &lt;- mask(accumThresh, densHUC12rast)
rHucs &lt;- mask(rHucs, landClip)
writeRaster(rHucs, &quot;D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/workingThoughProject/rHucs.tif&quot;, overwrite = TRUE)</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-32-1.png" width="50%" style="display: block; margin: auto;" />
<br></p>
<p>From here we can sample from these watersheds to get an idea of the distribution.</p>
<pre class="r"><code>global.dist &lt;- data.frame(sampleRandom(rHucs, size = 100000))
kableExtra::kable(table(global.dist), caption = &quot;Global Distribution from Random Sample&quot;)</code></pre>
<table>
<caption>
<span id="tab:unnamed-chunk-33">Table 2: </span>Global Distribution from Random Sample
</caption>
<thead>
<tr>
<th style="text-align:left;">
global.dist
</th>
<th style="text-align:right;">
Freq
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
96160
</td>
</tr>
<tr>
<td style="text-align:left;">
2
</td>
<td style="text-align:right;">
3840
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>So, as I said earlier; tedious, stringent, and most likely trivial. We ended up with 4%. So you can see how low a conservative stream prevalance rate would be. I’m sure you’re thinking well duh. But, I had to get it out there.</p>
</div>
<div id="data-leakage" class="section level3">
<h3>Data Leakage</h3>
<p><strong>Minimize Data Leakage</strong></p>
<p>Data leakage is a term used in data mining where information has been <em>leaked</em> and has had a <em>peak</em> on the training data <span class="citation">(Kaufman et al. 2012)</span>. It’s usually found when the results are “too good to be true” or unusual variables climb up to the top of variable importance (e.g. coordinates, elevation, ids, time-stamps, etc). Hopefully the investigation we did during predictor selection helped reduce that chance but mistakes can and will be made. Thus using some sort of feature selection technique like <span class="citation">Meyer et al. (2018)</span> or spatial cross validataion can help with mitigating variable leakage; however, there are some less obvious ways that data leakage can happen i.e. data splitting.</p>
<p>When splitting your data for training/tuning and testing, this is a perfect time for data leakage to happen. One common mistake is to downsample/upsample your raw data and then split it into training and test sets after doing this resampling procedure. You just committed the ultimate leakage sin. You might be thinking “this is so harmless” but this allows information from the training data to be passed to the test data via the resampling procedure, which can possibly allow the model to overfit by reducing the actual <em>population</em> thus possibly trimming the data (very subtle). Another is if you are imputing or transforming any data pre-data-splitting, then the test data has <em>seen</em> the training data and will lead to over-fitting in the model, again very subtle. Finally, when deriving cutoff thresholds it might be tempting to use the same data you used for training or some sort of post-hoc derivation, again this is leakage <span class="citation">(Kuhn and Johnson 2013)</span>. Therefore, to avoid these pitfalls we looked at data that could be surrogate variables (cause and effect section), we will transform data after data-splitting and during CV (i.e. test sets in CV can’t see transformed data, very subtle) or downsample during CV if needed and finally derive thresholds off an independent evaluation set or during the validation process using <code>recipes</code>. Since we have a lot of data we have the adantage of splitting the data into multiple sets that will help avoid these issues. However some times this isn’t the case so exploring these pitfalls should always be good practice to help us avoid the wrath of data leakage in the future.</p>
</div>
<div id="structures" class="section level3">
<h3>Structures</h3>
<p><strong>Access Dependance Structures</strong></p>
<p>Accessing dependance structures is a step recommended by <span class="citation">Roberts et al. (2017)</span> and should be considered common practice with any spatial prediction type analysis. The objective is to analyze your covariates (e.g. rasters) so that you can get an idea of the associated spatial autocorrelation levels (e.g. ranges from variogram). The method that is used in concurrence with <span class="citation">Roberts et al. (2017)</span> via <span class="citation">Valavi et al. (2018)</span> is a variogram type approach (isotopic). The main reason to use this procedure is that if you don’t structure your spatial data systematically (i.e. in this case by variograms) then you are likely going to underestimate or overestimate (depends on metrics) your error in your evaluation, again leading to over optimistic results and over-fitting in the models <span class="citation">(Roberts et al. 2017; Meyer et al. 2018, 2019)</span>.</p>
<p><span class="citation">Roberts et al. (2017)</span> and <span class="citation">Valavi et al. (2018)</span> suggest using a blocking system with different techniques (e.g. systematically, checkerboard, or by rows or columns) and then partitioning the sample space based on the set of variogram ranges (median distance selected) <span class="citation">(Valavi et al. 2018)</span>. This is a balanced approach to demarcating the dependance structures; however, there are covariates remaining with high spatial autocorrelation (i.e. median is the threshold). Again, no free lunch. However, there are ways to find a balance; we will search for this balance by testing four different structures, all with there inherent spatial autocorrelation ranges, e.g. 12th HUC, blockCV median, 14th HUC and K-means. The goal is to go big and small, i.e. minimal autocorrelation to a lot.</p>
<p>Below is how we got the block cv size and how we are adding HUCs to the structure cv using <span class="citation">Valavi et al. (2018)</span>. This is a really sweet package with great tools and interface options for spatial modelling! Here is a link to the vignette <a href="http://htmlpreview.github.io/?https://github.com/rvalavi/blockCV/blob/master/vignettes/BlockCV_for_SDM.html">blockCV</a>.</p>
<pre class="r"><code>remotes::install_github(&quot;rvalavi/blockCV&quot;, dependencies = TRUE)
library(blockCV)
library(sf)
library(raster)</code></pre>
<p>First we want to bring in our point data and our covariates.</p>
<pre class="r"><code>library(sf)
ptsSF &lt;- arc.open(&quot;D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/workingThoughProject/points_spaced30m.shp&quot;)  #points to the folder/feature
ptsSF &lt;- arc.select(ptsSF, c(&quot;copy_TWI_1&quot;)) #selects the data in the folder

ptsSF &lt;- arc.data2sf(ptsSF)
ptsSF &lt;- st_as_sf(data, coords = c(&quot;coords.x1&quot;,&quot;coords.x2&quot;))
pts
st_crs(ptsSF) &lt;- &quot;+proj=aea +lat_1=46 +lat_2=48 +lat_0=44 +lon_0=-109.5 +x_0=600000 +y_0=0 +datum=NAD83 +units=m +no_defs +ellps=GRS80 +towgs84=0,0,0&quot;
nrow(data)
topo_new &lt;- dropLayer(topo_opt_rad30, c(&quot;ndvias30agg&quot;, &quot;cpg30Deficit&quot;)) #covariate stack
topo_new</code></pre>
<p><br>
Plot to make sure everything is lined up. Looks good.</p>
<pre><code>## Warning in plot.sf(ptsSF[which(ptsSF$stream == 0), ], pch = 16, col = &quot;red&quot;, : ignoring all but the first attribute</code></pre>
<pre><code>## Warning in plot.sf(ptsSF[which(ptsSF$stream == 1), ], pch = 1, col = &quot;blue&quot;, : ignoring all but the first attribute</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-36-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p><br></p>
<p>Now we can figure out our ‘effictive range of spatial autocorrelation’ by using the function <code>spatialAutoRange</code> in <code>blockCV</code>. This is a cool function because it takes the covariates, calculates the range of autocorrelation (from <span class="math inline">\(n\)</span> sampled points), and then produces two plots showing the range of the covariates and the recommended block size for validation.</p>
<pre class="r"><code>sac &lt;- blockCV::spatialAutoRange(rasterLayer = topo_new,
                                 sampleNumber = 5000,
                                 doParallel = TRUE,
                                 showPlots = TRUE)</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-38-1.png" width="672" style="display: block; margin: auto;" />
Plots of variograms: lowest (TPI), median (UAA), highest (CWD).<br />
<br>
<img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-39-1.png" width="50%" /><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-39-2.png" width="50%" /><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-39-3.png" width="50%" />
<br></p>
<p>So as you can see there are some variables that are very spatially autocorrelated. The <code>BlockCV</code> package recommends the median range as a structure dimension and then disects the sample space into dimensions, e.g. blocks. From here you add the points and <code>BlockCV</code> will provide a sampling scheme for cross validation. Pretty sweet! Real quick, here’s the summary from the variograms giving the range with each covariate.</p>
<pre><code>## 
## Attaching package: &#39;kableExtra&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     group_rows</code></pre>
<table class="table table-striped table-hover table-condensed table-responsive" style="width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-40">Table 3: </span>Table of Range and Covariates
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
layers
</th>
<th style="text-align:right;">
range
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
2
</td>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
350.5236
</td>
</tr>
<tr>
<td style="text-align:left;">
6
</td>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
1096.7657
</td>
</tr>
<tr>
<td style="text-align:left;">
13
</td>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
2148.1797
</td>
</tr>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
2486.7891
</td>
</tr>
<tr>
<td style="text-align:left;">
8
</td>
<td style="text-align:left;">
ndwias30agg
</td>
<td style="text-align:right;">
2520.0715
</td>
</tr>
<tr>
<td style="text-align:left;">
5
</td>
<td style="text-align:left;">
vvsd30agg
</td>
<td style="text-align:right;">
2567.1247
</td>
</tr>
<tr>
<td style="text-align:left;">
17
</td>
<td style="text-align:left;">
B8_30agg
</td>
<td style="text-align:right;">
4329.5648
</td>
</tr>
<tr>
<td style="text-align:left;">
7
</td>
<td style="text-align:left;">
ndvi30yrRS
</td>
<td style="text-align:right;">
5378.3710
</td>
</tr>
<tr>
<td style="text-align:left;">
16
</td>
<td style="text-align:left;">
B4_30agg
</td>
<td style="text-align:right;">
5672.9572
</td>
</tr>
<tr>
<td style="text-align:left;">
3
</td>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
5715.8568
</td>
</tr>
<tr>
<td style="text-align:left;">
15
</td>
<td style="text-align:left;">
B3_30agg
</td>
<td style="text-align:right;">
5903.6377
</td>
</tr>
<tr>
<td style="text-align:left;">
4
</td>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
6286.4209
</td>
</tr>
<tr>
<td style="text-align:left;">
9
</td>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
10557.6102
</td>
</tr>
<tr>
<td style="text-align:left;">
11
</td>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
10940.0857
</td>
</tr>
<tr>
<td style="text-align:left;">
14
</td>
<td style="text-align:left;">
B2_30agg
</td>
<td style="text-align:right;">
11893.0245
</td>
</tr>
<tr>
<td style="text-align:left;">
12
</td>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
12188.1081
</td>
</tr>
<tr>
<td style="text-align:left;">
18
</td>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
14436.5249
</td>
</tr>
<tr>
<td style="text-align:left;">
10
</td>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
18410.0072
</td>
</tr>
</tbody>
</table>
<p><br></p>
<p>Now we can systematically seperate the blocks out with a k=10 for a 10-fold CV and a range from the derived median.</p>
<pre class="r"><code>sbMed &lt;- spatialBlock(speciesData = ptsSF, # presence-background data
                    species = &quot;stream&quot;,
                    rasterLayer = topo_new,
                    k = 10,
                      theRange = 5694,
                    selection = &quot;systematic&quot;,
                    biomod2Format = TRUE)</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-42-1.png" width="50%" style="display: block; margin: auto;" />
<br>
<br></p>
<p>Now we can partition the data by Hydrological Unit Codes (12th and 14th HUCs) into ‘blocks’ based on a systematic approach. Same thing: 10 folds, selection = “systematic”.</p>
<pre class="r"><code>HUC14SP &lt;- arc.open(&quot;D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/workingThoughProject/ksank14thclip.shp&quot;)  #points to the folder/feature
HUC14SP &lt;- arc.select(HUC14SP, c(&quot;FID&quot;)) #selects the data in the folder

HUC14SP &lt;- arc.data2sp(HUC14SP)

HUC14SP &lt;- spTransform(HUC14SP,CRSobj = crs(topo_opt_rad30))

sb14 &lt;- spatialBlock(speciesData = ptsSF, 
                    species = &quot;stream&quot;, 
                    rasterLayer = topo_new, 
                    blocks = HUC14SP,
                    k = 10,
                    selection = &quot;systematic&quot;)</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-44-1.png" width="672" /></p>
<pre class="r"><code>HUC12SP &lt;- arc.open(&quot;D:/Rcodes/Water_Prediction/Hird_Water_Prediction/waterD/waterPred/workingThoughProject/ksank12thclip.shp&quot;)  #points to the folder/feature
HUC12SP &lt;- arc.select(HUC12SP, c(&quot;FID&quot;)) #selects the data in the folder

HUC12SP &lt;- arc.data2sp(HUC12SP)

HUC12SP &lt;- spTransform(HUC12SP,CRSobj = crs(topo_opt_rad30))

sb12 &lt;- spatialBlock(speciesData = ptsSF, 
                    species = &quot;stream&quot;, 
                    rasterLayer = topo_new, 
                    blocks = HUC12SP,
                    k = 10,
                    selection = &quot;systematic&quot;)</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-46-1.png" width="672" />
<br></p>
<p>Finally, we can do a <code>kmeans</code> with a cluster of 20. This will be our small structure attempt.</p>
<pre class="r"><code>#this is the Leave-One-Out-CV (LOOCV) method (using a cluster of 20)
#need coordinates.
#remember to use the coordinates, that&#39;s why we&#39;ve kept them!

Mycluster &lt;- kmeans(data[,c(23,24)], (nrow(data)/20)) 

# add the new variable back to your dataframe here
data$spatial_cluster =Mycluster$cluster</code></pre>
<p>Now you can see the clusters.</p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-48-1.png" width="672" style="display: block; margin: auto;" /></p>
<p><br></p>
<p>Now bring in the blocks we created (<code>sb12</code>,<code>sb14</code>,<code>sb2</code>) and bind with our data frame <code>data</code> so that we can index these during CV.</p>
<pre class="r"><code>data &lt;- cbind(data, sbMed = sbMed$foldID, sb14 = sb14$foldID, sb12 = sb12$foldID)
data[1:20,c(23:26)]
data &lt;- data[,-c(28,29,30)]</code></pre>
<p><br></p>
</div>
</div>
<div id="evaluation-techniques" class="section level2">
<h2>Evaluation Techniques</h2>
<p><strong>Evaluation Techniques</strong></p>
<p>Building a model can seem pretty straight forward and easy, almost like a plug and chug; but, this will most likely lead to unreliable results and dissappointed end-users <span class="citation">(Kuhn and Johnson 2013)</span>. We want to correct for these potential oversights as discussed in earlier sections and equally not take so much time while doing so (i.e. model efficiency). Therefore, balancing validation/selection techniques with time will be the goal of this analysis so that future workflows can be performed in a modest amount of time while also achieving optimal model performance within a spatial context. Traditional ways of balancing these issues can be through different validation techniques (e.g., k-Fold Cross-Validation, bootstrapping (out-of-bag error), validation set approach, Leave-One-Out Cross-Validation (LOOCV), etc) and feature selection techniques (e.g., forward first, recursive, or natural feature extraction (lasso)) <span class="citation">(Friedman, Hastie, and Tibshirani 2001; James et al. 2013; Kuhn and Johnson 2013)</span>; however, within a spatial context these techniques can run into problems as found in <span class="citation">(Meyer et al. 2018, 2019; Roberts et al. 2017)</span>. Therefore we must account for these problems and use other techniques to lessen the effect of overfitting within a spatial context.</p>
<p>As I’ve already alluded to in previous sections, we will use a feature selection model from <span class="citation">Meyer et al. (2018)</span> which is a forward feature selection (ffs) type technique within then <code>CAST</code> package and compare with a recursive feature elimination (rfe) technique from <span class="citation">Kuhn and Johnson (2013)</span>. This is very similar to the approach that <span class="citation">Meyer et al. (2018)</span>;<span class="citation">Meyer et al. (2019)</span> has done. In addition, we will also use four different target-oriented cross-validation approaches to find a dependance structure balance between autocorrelation and evaluation (eg., HUC12, BlockCV, HUC14 and K-means). The importance of feature selection and evaluation (eg., cross-validation, out-of-bag error, etc) within a spatial context has been expressed in numerous papers <span class="citation">(Bahn and McGill 2013; Ives and Zhu 2006; Meyer et al. 2018, 2019; Roberts et al. 2017)</span>, and the the reason why we’re putting so much emphasis on this topic is that we want be confident about the performance statistics before the model is going into production, i.e. so that the end-user will not be mislead. How these frameworks play into management is a matter of the objectives and goals; therefore, in the spatial domain where highly flexible models (i.e. ensemble type models) are becoming the norm cation should be met.</p>
<p><strong>Feature Selection</strong></p>
<p>I highlighted some advantages of using a feature selection in previous sections, but there can also be some disadvantages as well. One of the most recognized problems with feed forward type selection (e.g. stepwise, forward first, etc) is that the model algorithm puts a threshold on how far the model will go before the <em>selections</em> stop , which leaves the possibility of important variables not being selected <span class="citation">(see Friedman, Hastie, and Tibshirani 2001; James et al. 2013; Kuhn and Johnson 2013; Meyer et al. 2018)</span>. To possibly account for this affect, there are ways or options within the <code>CAST</code> package to model all possible best subsets (bss), but will take ages! Discusssing this with one of the authors of <span class="citation">(Meyer et al. 2018, 2019)</span>, she said “I compared bss with fss for some examples and found that the ffs is doing a good job and rarely misses important variables.”</p>
<p>Therefore, ffs seems get it right a majority of the time. Is this enough? I think exploring the theory behind ffs within a spatial context might help explain this question or concern. To solve its problems of occasionally not picking an ‘important’ predictor (that is ffs) it emphasizes combinations of variables that reduce variance in such reduce overfitting. Again, there are trade-offs and it comes down to how much time and energy you want to put into capturing the covariate(s) (e.g. bss will do this) that will possibly increase model performance. For example, as discussed in earlier sections we want to avoid surrogate or geolocated-type variables because of the overfitting that occurs when these variables are in a model <span class="citation">(Meyer et al. 2018, 2019)</span>; therefore, by reducing the overfitting up-front (ffs) compared to the tradeoff of possibly missing an important variable during selection (i.e. interpretable or optimal, goals and objectives matter…) outweighs the cost of having an over-optimistic model for the end-user.</p>
<p>The compliment of ffs is rfe and <span class="citation">Meyer et al. (2019)</span> has shown that within a spatial context the rfe approach can lead to overfitting. This overfitting can happen due to the algorithm holding on to important variables that may have significant variance that goes unoticed <span class="citation">(Kuhn and Johnson 2013; Meyer et al. 2019)</span>. We want to see how these two feature selection approaches deal with the stream occurrence data. They most likely will be similar due to the stringent pre-processing we did and <span class="citation">Meyer et al. (2019)</span> has noted that rfe can achieve similar results with ffs; it just depends on the data being used. That is to say if you pre-process your data with ‘cause and effect’ in mind, then the differences may be obsolete. We will test this hypothesis.</p>
<p><strong>Tuning/Evaluation</strong></p>
<p>Tuning and evaluation go hand-in-hand. We will set aside a tuning/evaluation set that hasn’t seen the feature selection sets (e.g. ffs, RFE). The reason is due to data leakage and the overfitting caused by ovlapping, i.e. training with testing data. During this process we will tune the parameters of the models so that we can achieve otimal performance. There are different techniques to do this like a ‘search’ function for the most optimal parameters, which randomly searches different parameters in randomly uniform sample. I will use this for the gradient boosting machine (GBM) using methods from <span class="citation">Kuhn and Johnson (2013)</span> but not for random forest, due to random forest having minimal parameters. This will hopefully dismiss irrelevant parameters and focus on useful ones in a time-saving manner, i.e. less models will be fitted compared to a expansive grid approach.</p>
<p>Along with the tuning process we will also be doing cutoff threshold derivations so we can descriptively look into the interplay between specificity/sensitivity which some refer to recall/precision. This is a confusing topic that involves different confusing confusion matrix schemes online. In short, <code>caret</code> uses the <span class="citation">Altman and Bland (1994)</span> method which is normally what you’ll find in literature; however others ‘online’ will use an alternative which has the table flip-flopped, e.g. actual and predicted get switched but the terms don’t! Be aware of this and when reading this workflow refer to this link <a href="https://rdrr.io/cran/caret/man/sensitivity.html">here</a> or <a href="https://en.wikipedia.org/wiki/Confusion_matrix">here</a> for more on confusion matrix terminology and the specific method we’ll be using.</p>
<p>Within classification models and imbalanced data or rare data the goal is to optimize the splitting thresholds (e.g. standard cutoffs are at 50%) so that performance statistics can be reported to reflect the ‘on the ground’ transitions from ‘no stream’ to ‘stream’ appropriately. Thus one approach is to select for the optimal model by the Receiver operating characteristic (ROC). When compared to soley selecting for accuracy this can lead to a more balanced model performance between sensitivity/specificity (i.e. cutoff threshold of 50%); however, it is not always the optimal goal for the project like reducing false positives. To achieve optimal ROC there are methods like Youdens J or distance between Sens/Spec (Dist) that can increase ROC while balancing Sens/Spec. This is a pretty balanced approach because it balances the false positives and negatives.</p>
<p>By deriving a cutoff threshold that will balance the two type I/II errors, we can produce a more accurate model. There are tradeoffs of course, again no free lunch. The tradeoff come with giving or taking; from either false positive or negative. In our case, this will most likely reduce the false positives but increase the false negatives, which is what we want. So, deriving cutoff thresholds can help see these tradeoffs visually and can help find an optimal cutoff threshold to balance the two errors; however, it can also go against your objectives so be careful. We will just look at the possibilites but will ultimately go with the initial ROC/AUC value from the model,i.e. similar to <span class="citation">Hird et al. (2017)</span>. We could however pick a model that has the best specificity (e.g. less false positives) instead of using the ROC/AUC. This approach can help us achieve our objectives but the tradeoff is possibly having a model that is less balanced, which may be an alternative. To avoid any data leakage, typically you would want to do your tuning and evaluating (ROC/AUC) on a seperate hold out sets, e.g. tuning on one and evaluating on another. However, there are ways that you can combined these techniques together so that you don’t have to split the data up, which is what we will do.</p>
<p>The reason to do it within the tuning/evaluation set is 1). we don’t have to create another partition of data (e.g. a set), 2). From this we will be able to use more data in the final test set and also in the tuning/evalution set, 3). It keeps everything tidy. That being said, I also think by doing it all together and keeping the results tidy it will be easier for performance exploration and visualization. Within this process you can do any prep work that you would want to do without violating data leakage scenarios, e.g. transform, PCA, down-upsample, etc. We will do this with the PCA variables in our data set, e.g. B2, B3, B4, B8 and will bring some variables along for the ride to use later, e.g. <em>post hoc</em> visualization.</p>
</div>
</div>
<div id="modeling" class="section level1">
<h1>Modeling</h1>
<div id="model-selection" class="section level2">
<h2>Model Selection</h2>
<p><strong>Model Splitting</strong></p>
<p>Above in the data splitting section I proposed that we wanted to split the data into three partitions with the test data being the final model performance measure (sanity check). To do this we will split the data into two chunks and then split into test proportions once our final model is selected. This will hopefully give us a <em>natural</em> statistic into the final model performance.</p>
<pre class="r"><code>library(caret)
library(CAST)



set.seed(1234)
#split data into training and test data. 75% for training is the goal. 
datindex &lt;- createDataPartition(data$stream, list = FALSE, p=0.75)

train &lt;- data[datindex,]

test &lt;- data[-datindex,]

#then split the training data into two so we have &#39;overall&#39; 25% for feature selection and &#39;overall&#39; 50% for training.
set.seed(1234)
trainindex &lt;- createDataPartition(train$stream, list = FALSE, p = .66)

traintune &lt;- train[trainindex,]

trainsel &lt;- train[-trainindex,]

trainprevtune &lt;- train[trainindex,]

trainprevsel &lt;- train[-trainindex,]

#now for the tuning training set using prevalence
trainprevtuneSample1 &lt;- trainprevtune %&gt;% filter(stream == &quot;1&quot;) 

set.seed(1234)
 trainprevtuneSample1 &lt;- trainprevtuneSample1[sample(nrow(trainprevtuneSample1),274),]
 
trainprevtuneSample0 &lt;- trainprevtune %&gt;% filter(stream == &quot;0&quot;) 

  trainprevtune &lt;- data.frame(rbind(trainprevtuneSample0,trainprevtuneSample1))
  
  summary(trainprevtune$stream)

#now for the selection training set using prevalence
trainprevselSample1 &lt;- trainprevsel %&gt;% filter(stream == &quot;1&quot;) 

set.seed(1234)
 trainprevselSample1 &lt;- trainprevselSample1[sample(nrow(trainprevselSample1),141),]
 
trainprevselSample0 &lt;- trainprevsel %&gt;% filter(stream == &quot;0&quot;) 

  trainprevsel &lt;- data.frame(rbind(trainprevselSample0,trainprevselSample1))
  
  summary(trainprevsel$stream)</code></pre>
<p>As we’ve discussed earlier, another important step in evaluating spatial data is accounting for spatial autocorrelation. We can do this by doing spatial cross validation where folds are created at random; however, when specified (i.e., HUCs, block, cluster) these folds are systematically seperated by k-folds <span class="citation">(Roberts et al. 2017; Valavi et al. 2018)</span>. This will help correct for any spatial autocorrelation in the validation process, which will lead to more realistic results <span class="citation">(Meyer et al. 2018, 2019)</span>. The goal is to see how model performances react with different dependance structures. Hence finding a balance between ‘too large’ and ‘too small.’ Below we will use the <code>CAST</code> package to index these dependance structures.</p>
<pre class="r"><code>library(CAST)

#this is the index for the HUC12 method.
set.seed(1234)
indices12sel &lt;- CreateSpacetimeFolds(trainsel, spacevar = &quot;sb12&quot;, k = 10)

set.seed(1234)
indices12tune &lt;- CreateSpacetimeFolds(traintune,spacevar = &quot;sb12&quot;, k = 10) 

set.seed(1234)
indices12selprev &lt;- CreateSpacetimeFolds(trainprevsel, spacevar = &quot;sb12&quot;, k = 10)

set.seed(1234)
indices12tuneprev &lt;- CreateSpacetimeFolds(trainprevtune,spacevar = &quot;sb12&quot;, k = 10) 

#now for the blockCV method

set.seed(1234)
indicesMedsel &lt;- CreateSpacetimeFolds(trainsel, spacevar = &quot;sbMed&quot;, k = 10)

set.seed(1234)
indicesMedtune &lt;- CreateSpacetimeFolds(traintune,spacevar = &quot;sbMed&quot;, k = 10) 

set.seed(1234)
indicesMedselprev &lt;- CreateSpacetimeFolds(trainprevsel, spacevar = &quot;sbMed&quot;, k = 10)

set.seed(1234)
indicesMedtuneprev &lt;- CreateSpacetimeFolds(trainprevtune,spacevar = &quot;sbMed&quot;, k = 10) 

#this is the index for the HUC14 method

set.seed(1234)
indices14sel &lt;- CreateSpacetimeFolds(trainsel, spacevar = &quot;sb14&quot;, k = 10)

set.seed(1234)
indices14tune &lt;- CreateSpacetimeFolds(traintune,spacevar = &quot;sb14&quot;, k = 10) 

set.seed(1234)
indices14selprev &lt;- CreateSpacetimeFolds(trainprevsel, spacevar = &quot;sbMed&quot;, k = 10)

set.seed(1234)
indices14tuneprev &lt;- CreateSpacetimeFolds(trainprevtune,spacevar = &quot;sbMed&quot;, k = 10) 

#now for the cluster method

set.seed(1234)
indicesKsel &lt;- CreateSpacetimeFolds(trainsel, spacevar = &quot;spatial_cluster&quot;, k = 10)

set.seed(1234)
indicesKtune &lt;- CreateSpacetimeFolds(traintune,spacevar = &quot;spatial_cluster&quot;, k = 10) 

set.seed(1234)
indicesKselprev &lt;- CreateSpacetimeFolds(trainprevsel, spacevar = &quot;sbMed&quot;, k = 10)

set.seed(1234)
indicesKtuneprev &lt;- CreateSpacetimeFolds(trainprevtune,spacevar = &quot;sbMed&quot;, k = 10) </code></pre>
<p>Now that we have our training data let’s start building the models. We are going to do two feature selection models (e.g. rfe and ffs) per spatial CV for two different model types. So in this section there will be 8 different model results. First we need to create a <code>recipe</code> to handle the pca extraction during the feature selection.</p>
<pre class="r"><code>library(recipes)
library(tidyselect)

#for balanced data
rec_sel &lt;- 
  recipe(stream ~ ., data = trainsel) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, threshold = 0.9)

rec_tune &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, threshold = 0.9)

#for prevalence data
rec_selprev &lt;- 
  recipe(stream ~ ., data = trainprevsel) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, threshold = 0.9)

rec_tuneprev &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, threshold = 0.9)</code></pre>
<div id="rfe-random-forest" class="section level4">
<h4>RFE Random Forest</h4>
<p>Now we can start with the rfe feature selection. This feature selection technique <span class="citation">(Kuhn and Johnson 2013)</span> uses a recursive algorithm which models independent of different variable lengths and then selects the variables that leads to the lowest metric (e.g. Kappa, accuracy, etc). We will use the Kappa statistic as the feature selection criteria. Later in the tuning and the evaluation process we will use Specificity as a metric to evaluate the overall performance. This workflow is very similar to <span class="citation">Hird et al. (2017)</span> except we will use a feature selection step before tuning/evaluation.</p>
<p>We will use the default tuning grids for feature seletion below for both Random Forest and GBM (ffs and rfe). The reason has to do with time and it most likely won’t get you anything; however, if someone wants to try go right ahead. I’m going to use the tuning/validation set to beef up the models! This is more variable selection, but like I said you may want to add tuning and tailor how you want.</p>
<p><em>RFE 12th HUC Random Forest</em></p>
<pre class="r"><code>library(plyr)
#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#add to controls
rfeCtrl12 &lt;- rfeControl(
  functions = rfFuncs,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;,
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indices12sel$index
)
rfeCtrl12prev &lt;- rfeControl(
  functions = rfFuncs,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;,
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indices12selprev$index
)

#balanced model
set.seed(1234)
rfe12 &lt;- rfe(rec_sel,
  data = trainsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrl12,
  sizes = c(2:18))

#now for prevalence model
set.seed(1234)
rfe12prev &lt;- rfe(rec_selprev,
  data = trainprevsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrl12prev,
  sizes = c(2:18))

#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
83.51688
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
33.25004
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
28.87214
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
22.50602
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
19.26081
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
15.32609
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
15.16742
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
14.30337
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
13.12019
</td>
</tr>
<tr>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
12.35123
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B2
</td>
<td style="text-align:right;">
12.34902
</td>
</tr>
<tr>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
12.20689
</td>
</tr>
<tr>
<td style="text-align:left;">
ndwias30agg
</td>
<td style="text-align:right;">
12.13892
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
12.08997
</td>
</tr>
<tr>
<td style="text-align:left;">
ndvi30yrRS
</td>
<td style="text-align:right;">
10.92846
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
42.974124
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
16.954357
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
14.890134
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
10.886297
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
9.562900
</td>
</tr>
<tr>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
9.193509
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
8.729399
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
8.011614
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
7.409818
</td>
</tr>
</tbody>
</table>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-55-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p><em>RFE blockCV Random Forest</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#add to controls
rfeCtrlMed &lt;- rfeControl(
  functions = rfFuncs,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indicesMedsel$index
)

rfeCtrlMedprev &lt;- rfeControl(
  functions = rfFuncs,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indicesMedselprev$index
)
#balanced data
set.seed(1234)
rfeMed &lt;- rfe(rec_sel,
  data = trainsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrlMed,
  sizes = c(2:18))

#prevalence data
set.seed(1234)
rfeMedprev &lt;- rfe(rec_selprev,
  data = trainprevsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrlMedprev,
  sizes = c(2:18))
#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
82.58006
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
33.00096
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
29.01813
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
22.92511
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
19.06989
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
15.86478
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
15.22377
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
14.47780
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
13.69397
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
12.63457
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
42.937748
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
17.394339
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
15.040608
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
10.116063
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
9.655658
</td>
</tr>
<tr>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
7.748022
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
7.730162
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
7.693185
</td>
</tr>
<tr>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
7.261287
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
7.257008
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B2
</td>
<td style="text-align:right;">
7.137440
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
6.890446
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
6.463274
</td>
</tr>
</tbody>
</table>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-58-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p><em>RFE 14th HUC Random Forest</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#add to controls
rfeCtrl14 &lt;- rfeControl(
  functions = rfFuncs,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indices14sel$index
)

rfeCtrl14prev &lt;- rfeControl(
  functions = rfFuncs,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indices14selprev$index
)
#balanced data
set.seed(1234)
rfe14 &lt;- rfe(rec_sel,
  data = trainsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrl14,
  sizes = c(2:18))

#prevalence data
set.seed(1234)
rfe14prev &lt;- rfe(rec_selprev,
  data = trainprevsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrl14prev,
  sizes = c(2:18))

#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
83.26300
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
32.89858
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
29.05962
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
23.07001
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
19.21140
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
16.34066
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
15.36604
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
14.60449
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
13.67239
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
13.59942
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B2
</td>
<td style="text-align:right;">
13.53022
</td>
</tr>
<tr>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
11.86189
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
42.305642
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
16.951341
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
14.996234
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
10.234166
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
9.664406
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
7.896817
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
7.551560
</td>
</tr>
<tr>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
7.411923
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
6.618988
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
6.461227
</td>
</tr>
<tr>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
6.363360
</td>
</tr>
<tr>
<td style="text-align:left;">
vvsd30agg
</td>
<td style="text-align:right;">
5.873927
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
5.635370
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B2
</td>
<td style="text-align:right;">
5.582240
</td>
</tr>
<tr>
<td style="text-align:left;">
ndwias30agg
</td>
<td style="text-align:right;">
5.105362
</td>
</tr>
<tr>
<td style="text-align:left;">
ndvi30yrRS
</td>
<td style="text-align:right;">
3.913382
</td>
</tr>
</tbody>
</table>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-61-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p><em>RFE Cluster Random Forest</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#add to controls
rfeCtrlK &lt;- rfeControl(
  functions = rfFuncs,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indicesKsel$index
)

rfeCtrlKprev &lt;- rfeControl(
  functions = rfFuncs,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indicesKselprev$index
)

#balanced data
set.seed(1234)
rfeK &lt;- rfe(rec_sel,
  data = trainsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrlK,
  sizes = c(2:18))

#prevalence data
set.seed(1234)
rfeKprev &lt;- rfe(rec_selprev,
  data = trainprevsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrlKprev,
  sizes = c(2:18))


#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
81.91500
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
32.87138
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
28.58194
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
21.90547
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
18.39622
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
15.65414
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
15.01028
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
14.21273
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
12.94191
</td>
</tr>
<tr>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
11.79597
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B2
</td>
<td style="text-align:right;">
11.76070
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
11.66915
</td>
</tr>
<tr>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
11.66672
</td>
</tr>
<tr>
<td style="text-align:left;">
ndwias30agg
</td>
<td style="text-align:right;">
11.57453
</td>
</tr>
<tr>
<td style="text-align:left;">
ndvi30yrRS
</td>
<td style="text-align:right;">
11.26538
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
42.937748
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
17.394339
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
15.040608
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
10.116063
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
9.655658
</td>
</tr>
<tr>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
7.748022
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
7.730162
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
7.693185
</td>
</tr>
<tr>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
7.261287
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
7.257008
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B2
</td>
<td style="text-align:right;">
7.137440
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
6.890446
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
6.463274
</td>
</tr>
</tbody>
</table>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-64-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-66-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p>As we expected, when you go from large hold outs to small you will see a trend in performance.</p>
</div>
<div id="rfe-gbm" class="section level4">
<h4>RFE GBM</h4>
<p>Now we can move on to the GBM rfe. First we need to modify and bring in <code>gbm</code> properties for rfe so that it can recognize the gbm operations, similar to rfFuncs. This is due to rfe not having a predefined function for <code>gbm</code>.</p>
<pre class="r"><code>## this just brings in a basic list from which we can then modify
gbmRFE &lt;-  list(summary = defaultSummary,
               fit = function(x, y, first, last, ...){
                 library(randomForest)
                 randomForest(x, y, importance = first, ...)
               },
               pred = function(object, x)  predict(object, x),
               rank = function(object, x, y) {
                 vimp &lt;- varImp(object)
                 vimp &lt;- vimp[order(vimp$Overall,decreasing = TRUE),,drop = FALSE]
                 vimp$var &lt;- rownames(vimp)                  
                 vimp
               },
               selectSize = pickSizeBest,
               selectVar = pickVars)

#summary function is how are we storing the stats per resample
gbmRFE$summary &lt;- function (data, lev = NULL, model = NULL) 
{
  if (is.character(data$obs)) 
    data$obs &lt;- factor(data$obs, levels = lev)
  postResample(data[, &quot;pred&quot;], data[, &quot;obs&quot;])
}


#now bring in the gbm function and use method = &quot;gbm&quot;
gbmRFE$fit &lt;- function (x, y, first, last, ...) {
  library(gbm)
  caret::train(x, y, method = &quot;gbm&quot;)}

#this is the predict function from the &quot;gbm&quot; package
gbmRFE$pred &lt;- function (object, x) 
{
  tmp &lt;- predict(object, x)
  if (object$modelType == &quot;Classification&quot; &amp; object$control$classProbs) {
    out &lt;- cbind(data.frame(pred = tmp), as.data.frame(predict(object, 
                                                               x, type = &quot;prob&quot;)))
  }
  else out &lt;- tmp
  out
}

#this is the rank function from the &quot;gbm&quot; package
gbmRFE$rank &lt;- function(object, x, y){
  vimp &lt;- varImp(object, scale = TRUE)$importance
  if (!is.data.frame(vimp)) 
    vimp &lt;- as.data.frame(vimp)
  if (object$modelType == &quot;Regression&quot;) {
    vimp &lt;- vimp[order(vimp[, 1], decreasing = TRUE), , drop = FALSE]
  }
  else {
    if (all(levels(y) %in% colnames(vimp)) &amp; !(&quot;Overall&quot; %in% 
                                               colnames(vimp))) {
      avImp &lt;- apply(vimp[, levels(y), drop = TRUE], 1, 
                     mean)
      vimp$Overall &lt;- avImp
    }
  }
  vimp &lt;- vimp[order(vimp$Overall, decreasing = TRUE), , drop = FALSE]
  vimp$var &lt;- rownames(vimp)
  vimp
}

#selectSize and selectVar will stay the same</code></pre>
<p>Now we can start modeling. It should be noted that <code>gbm</code> does a internal feature selection so this might not be necessary; however, i’m investigating some more and still think that it is applicable for size of variables and trends.</p>
<p><em>RFE 12th HUC GBM</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#add to controls
rfeCtrl12g &lt;- rfeControl(
  functions = gbmRFE,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indices12sel$index
)

rfeCtrl12gprev &lt;- rfeControl(
  functions = gbmRFE,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indices12selprev$index
)

#Balanced 
set.seed(1234)
rfe12g &lt;- rfe(rec_sel,
  data = trainsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrl12g,
  sizes = c(2:18))

#Prevalence
set.seed(1234)
rfe12gprev &lt;- rfe(rec_selprev,
  data = trainprevsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrl12gprev,
  sizes = c(2:18))

#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
100.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
11.6228997
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
9.1523383
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
6.4603433
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
3.7626892
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
3.5671839
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
3.5347121
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
2.7427601
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B2
</td>
<td style="text-align:right;">
1.7476607
</td>
</tr>
<tr>
<td style="text-align:left;">
ndvi30yrRS
</td>
<td style="text-align:right;">
1.4295748
</td>
</tr>
<tr>
<td style="text-align:left;">
vvsd30agg
</td>
<td style="text-align:right;">
1.2350326
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
1.1218140
</td>
</tr>
<tr>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
1.1052137
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
0.7664776
</td>
</tr>
<tr>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
0.6972290
</td>
</tr>
<tr>
<td style="text-align:left;">
ndwias30agg
</td>
<td style="text-align:right;">
0.5769807
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
100.000000
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
23.677770
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
21.221456
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
13.001646
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
9.168694
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
8.606456
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B2
</td>
<td style="text-align:right;">
8.169847
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
8.153113
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
8.044979
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
7.360255
</td>
</tr>
<tr>
<td style="text-align:left;">
vvsd30agg
</td>
<td style="text-align:right;">
6.387338
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
6.041464
</td>
</tr>
<tr>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
5.812632
</td>
</tr>
<tr>
<td style="text-align:left;">
ndwias30agg
</td>
<td style="text-align:right;">
5.513158
</td>
</tr>
<tr>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
5.366556
</td>
</tr>
<tr>
<td style="text-align:left;">
ndvi30yrRS
</td>
<td style="text-align:right;">
4.466310
</td>
</tr>
</tbody>
</table>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-70-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p><em>RFE blockCV GBM</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#add to controls
rfeCtrlMedg &lt;- rfeControl(
  functions = gbmRFE,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indicesMedsel$index
)

rfeCtrlMedgprev &lt;- rfeControl(
  functions = gbmRFE,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indicesMedselprev$index
)

#balanced
set.seed(1234)
rfeMedg &lt;- rfe(rec_sel,
  data = trainsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrlMedg,
  sizes = c(2:18))

#prevalence
set.seed(1234)
rfeMedgprev &lt;- rfe(rec_selprev,
  data = trainprevsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrlMedgprev,
  sizes = c(2:18))

#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
100.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
11.3067246
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
8.4058929
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
5.7877504
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
3.8646041
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
3.0308583
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
2.9064551
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
2.8100509
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B2
</td>
<td style="text-align:right;">
1.4868424
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
1.2173641
</td>
</tr>
<tr>
<td style="text-align:left;">
ndvi30yrRS
</td>
<td style="text-align:right;">
1.1002770
</td>
</tr>
<tr>
<td style="text-align:left;">
vvsd30agg
</td>
<td style="text-align:right;">
1.0421211
</td>
</tr>
<tr>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
0.8201669
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
0.4961169
</td>
</tr>
<tr>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
0.2180094
</td>
</tr>
<tr>
<td style="text-align:left;">
ndwias30agg
</td>
<td style="text-align:right;">
0.1624402
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
100.000000
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
25.411118
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
23.708048
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
12.607525
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
9.653712
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
8.526657
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
8.196263
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B2
</td>
<td style="text-align:right;">
8.160256
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
7.502601
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
5.513605
</td>
</tr>
<tr>
<td style="text-align:left;">
vvsd30agg
</td>
<td style="text-align:right;">
5.473749
</td>
</tr>
<tr>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
5.337670
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
4.688262
</td>
</tr>
<tr>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
4.169500
</td>
</tr>
<tr>
<td style="text-align:left;">
ndwias30agg
</td>
<td style="text-align:right;">
4.003539
</td>
</tr>
<tr>
<td style="text-align:left;">
ndvi30yrRS
</td>
<td style="text-align:right;">
3.496428
</td>
</tr>
</tbody>
</table>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-73-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p><em>RFE 14th HUC GBM</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#add to controls
rfeCtrl14g &lt;- rfeControl(
  functions = gbmRFE,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indices14sel$index
)

rfeCtrl14gprev &lt;- rfeControl(
  functions = gbmRFE,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indices14selprev$index
)

#balanced
set.seed(1234)
rfe14g &lt;- rfe(rec_sel,
  data = trainsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrl14g,
  sizes = c(2:18))

#prevalence
set.seed(1234)
rfe14gprev &lt;- rfe(rec_selprev,
  data = trainprevsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrl14gprev,
  sizes = c(2:18))

#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
100.000000
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
11.646221
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
9.185082
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
6.084723
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
3.872173
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
3.612897
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
3.267076
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
3.184627
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
100.000000
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
23.978427
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
23.277920
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
12.187836
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
9.195571
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
8.000454
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
6.821554
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
6.545682
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B2
</td>
<td style="text-align:right;">
6.428239
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
6.304483
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
5.866341
</td>
</tr>
<tr>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
4.644523
</td>
</tr>
<tr>
<td style="text-align:left;">
ndwias30agg
</td>
<td style="text-align:right;">
3.972278
</td>
</tr>
<tr>
<td style="text-align:left;">
vvsd30agg
</td>
<td style="text-align:right;">
3.484467
</td>
</tr>
<tr>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
2.878771
</td>
</tr>
<tr>
<td style="text-align:left;">
ndvi30yrRS
</td>
<td style="text-align:right;">
1.585071
</td>
</tr>
</tbody>
</table>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-76-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p><em>RFE Kmeans GBM</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#add to controls
rfeCtrlKg &lt;- rfeControl(
  functions = gbmRFE,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indicesKsel$index
)

rfeCtrlKgprev &lt;- rfeControl(
  functions = gbmRFE,
  method = &quot;repeatedcv&quot;,
  repeats = 5,
  returnResamp = &quot;all&quot;, 
  verbose = FALSE, 
  allowParallel = TRUE,
  index = indicesKselprev$index
)

#balanced
set.seed(1234)
rfeKg &lt;- rfe(rec_sel,
  data = trainsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrlKg,
  sizes = c(2:18))

#prevalence
set.seed(1234)
rfeKgprev &lt;- rfe(rec_selprev,
  data = trainprevsel, metric = &quot;Kappa&quot;,
  rfeControl = rfeCtrlKgprev,
  sizes = c(2:18))

#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
100.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
11.0036543
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
8.5173055
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
6.5050789
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
3.5434939
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
3.2325680
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
2.9980272
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
2.9335504
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B2
</td>
<td style="text-align:right;">
1.5771027
</td>
</tr>
<tr>
<td style="text-align:left;">
vvsd30agg
</td>
<td style="text-align:right;">
1.2652670
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
1.1346387
</td>
</tr>
<tr>
<td style="text-align:left;">
ndvi30yrRS
</td>
<td style="text-align:right;">
0.9530277
</td>
</tr>
<tr>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
0.7642998
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
0.6926950
</td>
</tr>
<tr>
<td style="text-align:left;">
ndwias30agg
</td>
<td style="text-align:right;">
0.6084585
</td>
</tr>
<tr>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
0.3628058
</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Overall
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
accum30
</td>
<td style="text-align:right;">
100.0000000
</td>
</tr>
<tr>
<td style="text-align:left;">
tpi30agg
</td>
<td style="text-align:right;">
22.8016631
</td>
</tr>
<tr>
<td style="text-align:left;">
nppmmid30agg
</td>
<td style="text-align:right;">
22.7733825
</td>
</tr>
<tr>
<td style="text-align:left;">
cpg30precip
</td>
<td style="text-align:right;">
11.8369937
</td>
</tr>
<tr>
<td style="text-align:left;">
deficitRS
</td>
<td style="text-align:right;">
8.1688138
</td>
</tr>
<tr>
<td style="text-align:left;">
decid30RS
</td>
<td style="text-align:right;">
7.8369517
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B1
</td>
<td style="text-align:right;">
7.5783419
</td>
</tr>
<tr>
<td style="text-align:left;">
hdi30RS
</td>
<td style="text-align:right;">
6.1432806
</td>
</tr>
<tr>
<td style="text-align:left;">
cad30RS
</td>
<td style="text-align:right;">
5.8776606
</td>
</tr>
<tr>
<td style="text-align:left;">
pca_B2
</td>
<td style="text-align:right;">
5.8593121
</td>
</tr>
<tr>
<td style="text-align:left;">
twi30agg
</td>
<td style="text-align:right;">
4.8789386
</td>
</tr>
<tr>
<td style="text-align:left;">
ndwias30agg
</td>
<td style="text-align:right;">
4.5529335
</td>
</tr>
<tr>
<td style="text-align:left;">
vv30agg
</td>
<td style="text-align:right;">
3.9139695
</td>
</tr>
<tr>
<td style="text-align:left;">
vvsd30agg
</td>
<td style="text-align:right;">
3.2845994
</td>
</tr>
<tr>
<td style="text-align:left;">
npol30agg
</td>
<td style="text-align:right;">
2.5528054
</td>
</tr>
<tr>
<td style="text-align:left;">
ndvi30yrRS
</td>
<td style="text-align:right;">
0.3803842
</td>
</tr>
</tbody>
</table>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-79-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-81-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p>As we expected, when you go from large hold outs to small you will see a trend in performance.</p>
</div>
<div id="ffs-random-forest" class="section level4">
<h4>FFS Random Forest</h4>
<p>So with the FFS we will just use the default parameters for both Random Forest and GBM. This shouldn’t be too big of concern as I mentioned earlier. Kappa will still be the performance metric for selecting. First we need to prep the PCA variables before we do ffs.</p>
<pre class="r"><code>#NEED to prep the variables for PCA

set.seed(1234)
library(recipes)

rec_prepSel &lt;- prep(rec_sel,training = trainsel, retain = TRUE)
rec_prepSel$var_info %&gt;% filter(rec_prepSel$var_info$role == &quot;predictor&quot;) %&gt;% .$variable
set.seed(1234)
rec_selJuiced &lt;- juice(rec_prepSel,composition = &quot;data.frame&quot;)

predictorsRF &lt;- rec_selJuiced[,c(&quot;twi30agg&quot;,&quot;tpi30agg&quot;,&quot;accum30&quot;,&quot;vv30agg&quot;, &quot;vvsd30agg&quot;,&quot;npol30agg&quot;,&quot;ndvi30yrRS&quot;, &quot;ndwias30agg&quot;,&quot;nppmmid30agg&quot;,&quot;deficitRS&quot;,   &quot;hdi30RS&quot;,&quot;cad30RS&quot;,&quot;decid30RS&quot;,&quot;cpg30precip&quot;, &quot;pca_B1&quot;)]

responseRF &lt;- rec_selJuiced$stream

#now do for prevalence
rec_prepSelprev &lt;- prep(rec_selprev,training = trainprevsel, retain = TRUE)

set.seed(1234)
rec_selJuicedprev &lt;- juice(rec_prepSelprev,composition = &quot;data.frame&quot;)

predictorsRFprev &lt;- rec_selJuicedprev[,c(&quot;twi30agg&quot;,&quot;tpi30agg&quot;,&quot;accum30&quot;,&quot;vv30agg&quot;, &quot;vvsd30agg&quot;,&quot;npol30agg&quot;,&quot;ndvi30yrRS&quot;, &quot;ndwias30agg&quot;,&quot;nppmmid30agg&quot;,&quot;deficitRS&quot;,   &quot;hdi30RS&quot;,&quot;cad30RS&quot;,&quot;decid30RS&quot;,&quot;cpg30precip&quot;, &quot;pca_B1&quot;)]

responseRFprev &lt;- rec_selJuicedprev$stream</code></pre>
<p><em>FFS 12th HUC Random Forest</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#set up control
ctrl12rf &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indices12sel$index)
#set up control for prevalence
ctrl12rfprev &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indices12selprev$index)
#run with balanced
set.seed(1234)
ffs12rf &lt;- ffs(predictorsRF,responseRF, 
  metric = &quot;Kappa&quot;,
  method = &quot;rf&quot;,
  trControl = ctrl12rf)

#run with prevalence
set.seed(1234)
ffs12rfprev &lt;- ffs(predictorsRFprev,responseRFprev, 
  metric = &quot;Kappa&quot;,
  method = &quot;rf&quot;,
  trControl = ctrl12rfprev)


#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-84-1.png" width="1536" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-85-1.png" width="1632" style="display: block; margin: auto;" /></p>
<p><em>FFS BlockCV Medium Random Forest</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#set up control
ctrlMedrf &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indicesMedsel$index)
#set up control for prevalence
ctrlMedrfprev &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indicesMedselprev$index)
#run with balanced
set.seed(1234)
ffsMedrf &lt;- ffs(predictorsRF,responseRF, 
  metric = &quot;Kappa&quot;,
  method = &quot;rf&quot;,
  trControl = ctrlMedrf)

#run with prevalence
set.seed(1234)
ffsMedrfprev &lt;- ffs(predictorsRFprev,responseRFprev, 
  metric = &quot;Kappa&quot;,
  method = &quot;rf&quot;,
  trControl = ctrlMedrfprev)


#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-87-1.png" width="1536" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-88-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><em>FFS 14th HUC Random Forest</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#set up control
ctrl14rf &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indices14sel$index)
#set up control for prevalence
ctrl14rfprev &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indices14selprev$index)
#run with balanced
set.seed(1234)
ffs14rf &lt;- ffs(predictorsRF,responseRF, 
  metric = &quot;Kappa&quot;,
  method = &quot;rf&quot;,
  trControl = ctrl14rf)

#run with prevalence
set.seed(1234)
ffs14rfprev &lt;- ffs(predictorsRFprev,responseRFprev, 
  metric = &quot;Kappa&quot;,
  method = &quot;rf&quot;,
  trControl = ctrl14rfprev)


#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-90-1.png" width="1536" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-91-1.png" width="2304" style="display: block; margin: auto;" /></p>
<p><em>FFS Kmeans Random Forest</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#set up control
ctrlKrf &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indicesKsel$index)
#set up control for prevalence
ctrlKprev &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indicesKselprev$index)
#run with balanced
set.seed(1234)
ffsKrf &lt;- ffs(predictorsRF,responseRF, 
  metric = &quot;Kappa&quot;,
  method = &quot;rf&quot;,
  trControl = ctrlKrf)

#run with prevalence
set.seed(1234)
ffsKrfprev &lt;- ffs(predictorsRFprev,responseRFprev, 
  metric = &quot;Kappa&quot;,
  method = &quot;rf&quot;,
  trControl = ctrlKprev)


#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-93-1.png" width="1536" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-94-1.png" width="1920" style="display: block; margin: auto;" /></p>
</div>
<div id="ffs-gbm" class="section level4">
<h4>FFS GBM</h4>
<p>It won’t matter if we use <code>predictorsRF</code> and <code>predictorRFprev</code> so if you notice be aware that it’s fine.</p>
<p><em>FFS 12th HUC GBM</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#set up control
ctrl12g &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indices12sel$index)
#set up control for prevalence
ctrl12gprev &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indices12selprev$index)
#run with balanced
set.seed(1234)
ffs12g &lt;- ffs(predictorsRF,responseRF, 
  metric = &quot;Kappa&quot;,
  method = &quot;gbm&quot;,
  trControl = ctrl12g)

#run with prevalence
set.seed(1234)
ffs12gprev &lt;- ffs(predictorsRFprev,responseRFprev, 
  metric = &quot;Kappa&quot;,
  method = &quot;gbm&quot;,
  trControl = ctrl12gprev)


#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-96-1.png" width="1536" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-97-1.png" width="1824" style="display: block; margin: auto;" /></p>
<p><em>FFS BlockCV Medium GBM</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#set up control
ctrlMedg &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indicesMedsel$index)
#set up control for prevalence
ctrlMedgprev &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indicesMedselprev$index)
#run with balanced
set.seed(1234)
ffsMedg &lt;- ffs(predictorsRF,responseRF, 
  metric = &quot;Kappa&quot;,
  method = &quot;gbm&quot;,
  trControl = ctrlMedg)

#run with prevalence
set.seed(1234)
ffsMedgprev &lt;- ffs(predictorsRFprev,responseRFprev, 
  metric = &quot;Kappa&quot;,
  method = &quot;gbm&quot;,
  trControl = ctrlMedgprev)


#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-99-1.png" width="1536" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-100-1.png" width="1824" style="display: block; margin: auto;" /></p>
<p><em>FFS 14th HUC GBM</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#set up control
ctrl14g &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indices14sel$index)
#set up control for prevalence
ctrl14gprev &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indices14selprev$index)
#run with balanced
set.seed(1234)
ffs14g &lt;- ffs(predictorsRF,responseRF, 
  metric = &quot;Kappa&quot;,
  method = &quot;gbm&quot;,
  trControl = ctrl14g)

#run with prevalence
set.seed(1234)
ffs14gprev &lt;- ffs(predictorsRFprev,responseRFprev, 
  metric = &quot;Kappa&quot;,
  method = &quot;gbm&quot;,
  trControl = ctrl14gprev)


#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-102-1.png" width="1536" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-103-1.png" width="1824" style="display: block; margin: auto;" /></p>
<p><em>FFS Kmeans GBM</em></p>
<pre class="r"><code>#bring in cores
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

#set up control
ctrlKg &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indicesKsel$index)
#set up control for prevalence
ctrlKgprev &lt;- trainControl(method=&quot;repeatedcv&quot;,
                     repeats = 5,
                     allowParallel = TRUE,
                     returnResamp = &quot;all&quot;, 
                     verbose = FALSE, 
                     index = indicesKselprev$index)
#run with balanced
set.seed(1234)
ffsKg &lt;- ffs(predictorsRF,responseRF, 
  metric = &quot;Kappa&quot;,
  method = &quot;gbm&quot;,
  trControl = ctrlKg)

#run with prevalence
set.seed(1234)
ffsKgprev &lt;- ffs(predictorsRFprev,responseRFprev, 
  metric = &quot;Kappa&quot;,
  method = &quot;gbm&quot;,
  trControl = ctrlKgprev)


#now remove cluster. consistency...
stopCluster(cluster)
registerDoSEQ()</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-105-1.png" width="1536" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-106-1.png" width="1824" style="display: block; margin: auto;" />
## Model Performance</p>
</div>
<div id="quick-intro" class="section level4">
<h4>Quick Intro</h4>
<p><strong>Model Performance</strong></p>
<p>In this section we will now start to tune the selected variables from the feature selection process in the earlier section. This is where we will really try to optimize the performance using different techniques and approaches. There are different ways (advantages and disadvantages) to tuning certain model types. Random forest is pretty straight foward since it has only two parameters (e.g. mtry and ntrees) but GBM has multiple and can be sensitive to certain tuning schemes <span class="citation">(Kuhn and Johnson 2013)</span>. Therefore, it should be handled with care when exploring tuning options. Also, depending on what the objectives are for your project or study will ultimately direct your tuning and evaluation techniques. For more details on the ‘why are we tuning?’ go to the evaluation techniques section as that will give the rationale. This is just the nuts and bolts, so lots of graphs and code!</p>
</div>
<div id="rfe-downsizing" class="section level4">
<h4>RFE downsizing</h4>
<p>With rfe we end up with a lot of subsets (e.g. important variables), which we then need to decide how to filter or choose. Let us suppose we took a subset with the highest Kappa statistic, which contains 14 variables, but there were 5 other subsets with 4,5,6,7,10 variables within 2% of the Kappa value. Then it can be advantageous to take the one with the least amount of variables (e.g. curse of dimensionality) within a certain range (e.g. 1-5%). We could also look at the ‘one standard error’ approach by <span class="citation">Breiman et al. (1984)</span> and take the least complex model (e.g. low variable or parameter) within one standard error of the highest performing metric. These all have their trade-offs and some approaches work better for different types of models or feature selection; however, it’s prudent to explore these options and know the costs associated with them.</p>
<p>The goal is to not fall into the trap of doing this for every model selection or feature selection process, e.g. feature selection vs. feature engineering. In our case we are using it to trim down the rfe feature selection process and not the final GBM or random forest models. Also, it wouldn’t be appropriate to use with ffs, since ffs is essentially doing it for us. Thus if we use it for tuning (i.e. feature engineering) then we need to be careful because of different tuning parameters that are involved with the process. This is very subtle but should be highlighted. For example, how is a random forest model with 2 mtry and 1000 trees less complex than a model with 6 mtry and 250 trees? This is just with random forest, which only has two free parameters! This only gets more complicated with GBM, which has 4-5 free parameters and can lead to a very subjective selection process using the ‘least complex’ approach <span class="citation">(Kuhn and Johnson 2013)</span>.</p>
<p>Therefore, with rfe we will look at both the standard error and tolerance approach. Hence the highest performing feature selection might not be the model we pick and tune, i.e. this is the default function of rfe. If this is too confusing I appologize and it’s my inability to express this concept (guilty as charged); however, what I’m trying to say is that by selecting the model based on performance (default settings) results should be handled carefully. Hopefully the descriptions below from the function manual will help explain this process more clearly or for more information go to <a href="https://topepo.github.io/caret/model-training-and-tuning.html#choosing-the-final-model">topepo</a>.</p>
<p>“<code>oneSE</code> is a rule in the spirit of the”one standard error" rule of <span class="citation">Breiman et al. (1984)</span>, who suggest that the tuning parameter associated with the best performance may over fit. They suggest that the simplest model within one standard error of the empirically optimal model is the better choice. This assumes that the models can be easily ordered from simplest to most complex (see the Details section below).</p>
<p><code>tolerance</code> takes the simplest model that is within a percent tolerance of the empirically optimal model. For example, if the largest Kappa value is 0.5 and a simpler model within 3 percent is acceptable, we score the other models using (x - 0.5)/0.5 * 100. The simplest model whose score is not less than 3 is chosen (in this case, a model with a Kappa value of 0.35 is acceptable)."</p>
<footer>
— Max Kuhn
</footer>
<p><br></p>
<p>Here’s a function below that will take different tolerance inputs and graph them so we can see how the rfe subsets react with certain tolerance values. This will hopefully give us an idea of some of the gains we can get from reducing dimensions while keeping performance relatively close to the maximium.</p>
<pre class="r"><code>toltune &lt;- function(object, len, metric = &quot;&quot;, title = &quot;&quot;, plot = TRUE){
  
  object &lt;- object$results
  res = integer()
  for (i in 1:len){
    
    res[i] &lt;- tolerance(object, metric = metric, tol = i,maximize = TRUE)  
    
  }
  tolit &lt;- object[res,1:6]
  tolit$tolerance &lt;- seq(1,len, 1)
  
  if (plot == &quot;TRUE&quot;){
    
  pp &lt;-  tolit %&gt;% ggplot(aes_string(&quot;tolerance&quot;,metric)) + 
      geom_point(aes(color = factor(Variables)), size = 3) + geom_line() + 
      ggtitle(paste(title),&quot;statistic against tolerance values&quot;) + 
    scale_x_continuous(breaks = 1:len) +
  labs(color = &quot;# Variables&quot;)
 
 
  
  } else {
    
  }
    
  
  return(list(tolit, pp))
  
}</code></pre>
<p><br></p>
<p>Now we can look at the different rfe models compared to the tolerance ranges. Ideally we want to pick the least complex model and in our case this would be related to variable size. The basic function above helps us do this.</p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-108-1.png" width="864" style="display: block; margin: auto;" />
<br></p>
<p>As you can see it’s nice to look at how these different variable subsets plot against a range of tolerances. This will hopefully give us a better idea of what subset to choose and how variables/models are reacting with rfe. It seems like the random forest model flattens out when decreasing in tolerance and GBM steadily decreases as you can see above. Not sure what to make of this yet, so comments or thoughts would be much appreciated. Now we can look at the one standard error approach.</p>
<p>Let’s make a function so we can handle all the models. Create a list with all the models and then we can iterate through them and save the <code>oneSD</code> result.</p>
<pre class="r"><code>oneStan &lt;- data.frame()

oneReturn &lt;- function(objlist, metric = &quot;&quot;, num, maximize = TRUE){
  

  y &lt;- NULL
 for (i in 1:length(objlist)){
  
  object &lt;- objlist[[i]]
    
   object &lt;- object$results
  
  a &lt;- oneSE(object, metric = &quot;Kappa&quot;, num = 10 , maximize = TRUE)
  
  a &lt;- object[a,]
    y &lt;- rbind(y, a)
    
  }
  return(y)
}

oneR &lt;- oneReturn(objlist, &quot;Kappa&quot;, num = 10)
oneR1 &lt;- oneReturn(objlist2,&quot;Kappa&quot;, num = 10)</code></pre>
<p><br></p>
<p>We can now plot them to see how the add up. Not in order, sorry.</p>
<pre class="r"><code>oneR %&gt;% ggplot(aes(model, Kappa, color = factor(model))) + geom_point(size = 5) + ggtitle(&quot;Balanced oneSD Kappa values per Model&quot;)</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-110-1.png" width="960" style="display: block; margin: auto;" /></p>
<pre class="r"><code>oneR1 %&gt;% ggplot(aes(model, Kappa, color = factor(model))) + geom_point(size = 5) + ggtitle(&quot;Prevalence oneSD Kappa values per Model&quot;)</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-110-2.png" width="960" style="display: block; margin: auto;" />
<br></p>
<p>Now we can add the <code>tolerance</code> selection and see how they add up between the two methods. To choose the <code>tolerance</code> group I went with the closest to the highest performance, e.g. flat sections that still had high performance. Thus it was easy with random forest but GBM only lost a few variables, so I was a little more conservative. We can now see below that Both methods look pretty close to each other so I feel pretty comfortable using either the <code>tolerance</code> approach or the <code>oneR</code> approach. The <code>oneR</code> approach seems to be a lot easier and less descriptive so I’ll most likely use that to get the final subset from rfe.</p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-111-1.png" width="960" style="display: block; margin: auto;" /><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-111-2.png" width="960" style="display: block; margin: auto;" /></p>
<p><br></p>
</div>
<div id="rfe-tuning-random-forest" class="section level4">
<h4>RFE tuning Random Forest</h4>
<p>Now that we’ve figured out which rfe subset we are going to use we can start tuning the parameters (e.g. trees, depth, etc). This tuning process will also include the <code>thresholder</code> function from <code>caret</code> to optimize the cutoff threshold in the response after we find the best model using Specificity.This is a similar approach to <span class="citation">Hird et al. (2017)</span> were AUC was used to tune the model and then Youdens J was used to find the optimal classifying threshold. However, we will be using Specificity and Youdens J, which should give us a model that can perform well on the naturally imbalanced data.</p>
<table class="table table-striped" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-112">Table 4: </span>Table of ‘One Standard Error’ Kappa Values per Model; Balanced
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Variables
</th>
<th style="text-align:right;">
Kappa
</th>
<th style="text-align:left;">
model
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
4
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.5940055
</td>
<td style="text-align:left;">
RFE RF12
</td>
</tr>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
0.5630988
</td>
<td style="text-align:left;">
RFE GBM12
</td>
</tr>
<tr>
<td style="text-align:left;">
41
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.6205813
</td>
<td style="text-align:left;">
RFE RFMed
</td>
</tr>
<tr>
<td style="text-align:left;">
5
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
0.6144926
</td>
<td style="text-align:left;">
RFE GBM Med
</td>
</tr>
<tr>
<td style="text-align:left;">
42
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.6429501
</td>
<td style="text-align:left;">
RFE RF14
</td>
</tr>
<tr>
<td style="text-align:left;">
51
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
0.6336356
</td>
<td style="text-align:left;">
RFE GBM 14
</td>
</tr>
<tr>
<td style="text-align:left;">
43
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.6967188
</td>
<td style="text-align:left;">
RFE RFK
</td>
</tr>
<tr>
<td style="text-align:left;">
52
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
0.6721744
</td>
<td style="text-align:left;">
RFE GBM K
</td>
</tr>
</tbody>
</table>
<table class="table table-striped" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:unnamed-chunk-112">Table 4: </span>Table of ‘One Standard Error’ Kappa Values per Model; Prevalence
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Variables
</th>
<th style="text-align:right;">
Kappa
</th>
<th style="text-align:left;">
model
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
6
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0.4339848
</td>
<td style="text-align:left;">
RFEprev GBM12
</td>
</tr>
<tr>
<td style="text-align:left;">
4
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.4352672
</td>
<td style="text-align:left;">
RFEprev RF12
</td>
</tr>
<tr>
<td style="text-align:left;">
3
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0.4419343
</td>
<td style="text-align:left;">
RFEprev RFMed
</td>
</tr>
<tr>
<td style="text-align:left;">
41
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
0.4855202
</td>
<td style="text-align:left;">
RFEprev GBM Med
</td>
</tr>
<tr>
<td style="text-align:left;">
5
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
0.4947319
</td>
<td style="text-align:left;">
RFEprev RF14
</td>
</tr>
<tr>
<td style="text-align:left;">
12
</td>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
0.5167132
</td>
<td style="text-align:left;">
RFEprev GBM 14
</td>
</tr>
<tr>
<td style="text-align:left;">
31
</td>
<td style="text-align:right;">
4
</td>
<td style="text-align:right;">
0.4419343
</td>
<td style="text-align:left;">
RFEprev RFK
</td>
</tr>
<tr>
<td style="text-align:left;">
61
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
0.4862877
</td>
<td style="text-align:left;">
RFEprev GBM K
</td>
</tr>
</tbody>
</table>
<p><em>RFE 12th HUC Random Forest Tune</em></p>
<pre class="r"><code>#get variable subset from oneSD results
library(recipes)
rfe12$optVariables[1:5]
rfe12prev$optVariables[1:5]

levels(traintune$stream) &lt;- c(&quot;X0&quot;,&quot;X1&quot;)

rec_tune12 &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-cpg30precip,-cad30RS,-stream, new_role = &quot;bring along&quot;)

rec_tune12prev &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-cpg30precip,-cad30RS,-stream, new_role = &quot;bring along&quot;)

rec_tune12prevDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  step_downsample(stream) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-cpg30precip,-cad30RS,-stream, new_role = &quot;bring along&quot;)

customRF &lt;- getModelInfo(model = &quot;rf&quot;, regex = FALSE)[[1]]

#make custom parameters that we&#39;ll use on all random forest models
names(customRF)

prm &lt;- data.frame(parameter = c(&quot;mtry&quot;, &quot;ntree&quot;),
                  class = rep(&quot;numeric&quot;,2),
                  label = c(&quot;#Random Predictors&quot;, &quot;#of Trees&quot;))

customRF$parameters &lt;- prm

customRF$grid &lt;- function(x, y, len = NULL, search = &quot;grid&quot;) {
                    if(search == &quot;grid&quot;) {
                      out &lt;- data.frame(mtry = caret::var_seq(p = ncol(x), 
            classification = is.factor(y), len = len))
                    } else {
                      out &lt;- data.frame(mtry = unique(sample(1:ncol(x), size = len, replace = TRUE)))
                    }
                  }

customRF$fit &lt;- function(x, y, wts, param, lev, last, classProbs, ...){
                    randomForest::randomForest(x, y, mtry = param$mtry,ntree = param$ntree, ...)}</code></pre>
<pre class="r"><code>cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
rfe12tune &lt;- train(rec_tune12, data = traintune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:4,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indices12tune$index,
                                       summaryFunction = customRFsum))

set.seed(1234)
rfe12tuneprev &lt;- train(rec_tune12prev, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:4,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indices12tuneprev$index,
                                       summaryFunction = customRFsum))

set.seed(1234)
rfe12tuneprevDS &lt;- train(rec_tune12prevDS, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:4,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indices12tuneprev$index,
                                       summaryFunction = customRFsum))

stopCluster(cluster)
registerDoSEQ()

rfe12tuneThresh &lt;- thresholder(rfe12tune, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying
rfe12tuneprevThresh &lt;- thresholder(rfe12tuneprev, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying
rfe12tuneprevThreshDS &lt;- thresholder(rfe12tuneprevDS, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2136  468
##         X1  597 2793
##                             
##  Accuracy (average) : 0.8223</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2644  137
##         X1   89  137
##                             
##  Accuracy (average) : 0.9248</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2251   57
##         X1  482  217
##                             
##  Accuracy (average) : 0.8208</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-115-1.png" width="1248" style="display: block; margin: auto;" /></p>
<p><em>RFE Med BlockCV Random Forest Tune</em></p>
<pre class="r"><code>#get variable subset from oneSD results
library(recipes)
library(caret)
library(CAST)
rfeMed$optVariables[1:5]
rfeMedprev$optVariables[1:4]

rec_tuneMed &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-cpg30precip,-cad30RS,-stream, new_role = &quot;bring along&quot;)

rec_tuneMedprev &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-cpg30precip,-stream, new_role = &quot;bring along&quot;)

rec_tuneMedprevDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  step_downsample(stream) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-cpg30precip,-stream, new_role = &quot;bring along&quot;)


cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
rfeMedtune &lt;- train(rec_tuneMed, data = traintune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:4,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indicesMedtune$index,
                                       summaryFunction = multiClassSummary))

set.seed(1234)
rfeMedtuneprev &lt;- train(rec_tuneMedprev, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:3,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indicesMedtuneprev$index,
                                       summaryFunction = multiClassSummary))

set.seed(1234)
rfeMedtuneprevDS &lt;- train(rec_tuneMedprevDS, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:3,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indicesMedtuneprev$index,
                                       summaryFunction = multiClassSummary))
stopCluster(cluster)
registerDoSEQ()

rfeMedtuneThresh &lt;- thresholder(rfeMedtune, threshold = seq(0,1,.02))
rfeMedtuneprevThresh &lt;- thresholder(rfeMedtuneprev, threshold = seq(0,1,.02))
rfeMedtuneprevThreshDS &lt;- thresholder(rfeMedtuneprevDS, threshold = seq(0,1,.02))</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2134  474
##         X1  599 2787
##                            
##  Accuracy (average) : 0.821</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2666  133
##         X1   67  141
##                             
##  Accuracy (average) : 0.9335</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2168   45
##         X1  565  229
##                             
##  Accuracy (average) : 0.7971</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-117-1.png" width="1248" style="display: block; margin: auto;" /></p>
<p><em>RFE 14th HUC Random Forest Tune</em></p>
<pre class="r"><code>#get variable subset from oneSD results

rfe14$optVariables[1:5]
rfe14prev$optVariables[1:6]

rec_tune14 &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-cpg30precip,-cad30RS,-stream, new_role = &quot;bring along&quot;)

rec_tune14prev &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-cpg30precip,-cad30RS,-hdi30RS,-stream, new_role = &quot;bring along&quot;)

rec_tune14prevDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-cpg30precip,-cad30RS,-hdi30RS,-stream, new_role = &quot;bring along&quot;) %&gt;% 
  step_downsample(stream)


cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
rfe14tune &lt;- train(rec_tune14, data = traintune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:4,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indices14tune$index,
                                       summaryFunction = multiClassSummary))

set.seed(1234)
rfe14tuneprev &lt;- train(rec_tune14prev, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:5,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indices14tuneprev$index,
                                       summaryFunction = multiClassSummary))


set.seed(1234)
rfe14tuneprevDS &lt;- train(rec_tune14prevDS, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:5,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indices14tuneprev$index,
                                       summaryFunction = multiClassSummary))
stopCluster(cluster)
registerDoSEQ()

rfe14tuneThresh &lt;- thresholder(rfe14tune, threshold = seq(0,1,.02))
rfe14tuneprevThresh &lt;- thresholder(rfe14tuneprev, threshold = seq(0,1,.02))
rfe14tuneprevThreshDS &lt;- thresholder(rfe14tuneprevDS, threshold = seq(0,1,.02))</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2242  517
##         X1  491 2744
##                             
##  Accuracy (average) : 0.8318</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2488  118
##         X1   43  122
##                             
##  Accuracy (average) : 0.9419</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2254   54
##         X1  479  220
##                             
##  Accuracy (average) : 0.8227</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-119-1.png" width="1248" style="display: block; margin: auto;" /></p>
<p><em>RFE Kmeans Random Forest Tune</em></p>
<pre class="r"><code>#get variable subset from oneSD results
library(recipes)
rfeK$optVariables

rec_tuneK &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-cpg30precip,-cad30RS,-stream, new_role = &quot;bring along&quot;)

rec_tuneKprev &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-cpg30precip,-stream, new_role = &quot;bring along&quot;)

rec_tuneKprevDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-cpg30precip,-stream, new_role = &quot;bring along&quot;) %&gt;%
  step_downsample(stream, skip = TRUE)
  
  
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
rfeKtune &lt;- train(rec_tuneK, data = traintune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:4,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indicesKtune$index,
                                       summaryFunction = multiClassSummary))

set.seed(1234)
rfeKtuneprev &lt;- train(rec_tuneKprev, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:3,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indicesKtuneprev$index,
                                       summaryFunction = multiClassSummary))
set.seed(1234)
rfeKtuneprevDS &lt;- train(rec_tuneKprevDS, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:3,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indicesKtuneprev$index,
                                       summaryFunction = multiClassSummary))

stopCluster(cluster)
registerDoSEQ()

rfeKtuneThresh &lt;- thresholder(rfeKtune, threshold = seq(0,1,.02))
rfeKtuneprevThresh &lt;- thresholder(rfeKtuneprev, threshold = seq(0,1,.02))
rfeKtuneprevThreshDS &lt;- thresholder(rfeKtuneprevDS, threshold = seq(0,1,.02))</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2338  431
##         X1  395 2830
##                             
##  Accuracy (average) : 0.8622</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2666  133
##         X1   67  141
##                             
##  Accuracy (average) : 0.9335</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2182   53
##         X1  551  221
##                             
##  Accuracy (average) : 0.7991</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-121-1.png" width="1248" style="display: block; margin: auto;" /></p>
</div>
<div id="rfe-tuning-gbm" class="section level4">
<h4>RFE tuning GBM</h4>
<p><em>RFE 12th HUC GBM Tune</em></p>
<pre class="r"><code>#we&#39;ll use this tunegrid for all gbm models
gbmGrid &lt;- expand.grid(interaction.depth = c(1,2,4,6,8), n.trees = c(500,1000,1500,2000,3000), shrinkage = c(0.001,.05,0.1,0.2,0.5), n.minobsinnode = c(10,15,25))
#get variable subset from oneSD results
oneR
oneR1
rfe12gprev$optVariables[1:7]
runi

rec_tune12g &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-stream, new_role = &quot;bring along&quot;) 

rec_tune12gprev &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-tpi30agg,-cpg30precip,-decid30RS,-deficitRS,-stream,-B2_30agg,-B3_30agg,-B4_30agg,-B8_30agg, new_role = &quot;bring along&quot;) %&gt;%
  step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;,num_comp = 1)

rec_tune12gprevDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-tpi30agg,-cpg30precip,-decid30RS,-deficitRS,-stream,-B2_30agg,-B3_30agg,-B4_30agg,-B8_30agg, new_role = &quot;bring along&quot;) %&gt;% 
  step_downsample(stream) %&gt;% 
  step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, num_comp = 1)
  
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
rfe12gtune &lt;- train(rec_tune12g, data = traintune,
              method = &quot;gbm&quot;, tuneLength = 20,
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indices12tune$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
rfe12gtuneprev &lt;- train(rec_tune12gprev, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indices12tuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
rfe12gtuneprevDS &lt;- train(rec_tune12gprevDS, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indices12tuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)
stopCluster(cluster)
registerDoSEQ()

rfe12gtuneThresh &lt;- thresholder(rfe12gtune, threshold = seq(0,1,.02))
rfe12gtuneprevThresh &lt;- thresholder(rfe12gtuneprev, threshold = seq(0,1,.02))
rfe12gtuneprevThreshDS &lt;- thresholder(rfe12gtuneprevDS, threshold = seq(0,1,.02))</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2205  550
##         X1  528 2711
##                             
##  Accuracy (average) : 0.8202</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2733  274
##         X1    0    0
##                             
##  Accuracy (average) : 0.9089</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0  774   47
##         X1 1959  227
##                             
##  Accuracy (average) : 0.3329</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-123-1.png" width="1248" style="display: block; margin: auto;" /></p>
<p><em>RFE blockCV Med GBM Tune</em></p>
<pre class="r"><code>#get variable subset from oneSD results
oneR
oneR1
rfeMedg$optVariables[1:6]
rfeMedgprev$optVariables[1:5]

library(recipes)

rec_tuneMedg &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-tpi30agg,-cpg30precip,-decid30RS,-deficitRS,-stream, new_role = &quot;bring along&quot;) 

rec_tuneMedgprev &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-tpi30agg,-cpg30precip,-stream,-B2_30agg,-B3_30agg,-B4_30agg,-B8_30agg, new_role = &quot;bring along&quot;) %&gt;% 
  step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, threshold = 0.9, num_comp = 1)
  
rec_tuneMedgprevDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-tpi30agg,-cpg30precip,-stream,-B2_30agg,-B3_30agg,-B4_30agg,-B8_30agg, new_role = &quot;bring along&quot;) %&gt;% 
  step_downsample(stream) %&gt;% 
  step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, threshold = 0.9, num_comp = 1)

cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
rfeMedgtune &lt;- train(rec_tuneMedg, data = traintune,
              method = &quot;gbm&quot;,
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indicesMedtune$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
rfeMedgtuneprev &lt;- train(rec_tuneMedgprev, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indicesMedtuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
rfeMedgtuneprevDS &lt;- train(rec_tuneMedgprevDS, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indicesMedtuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

stopCluster(cluster)
registerDoSEQ()

rfeMedgtuneThresh &lt;- thresholder(rfeMedgtune, threshold = seq(0,1,.02))
rfeMedgtuneprevThresh &lt;- thresholder(rfeMedgtuneprev, threshold = seq(0,1,.02))
rfeMedgtuneprevThreshDS &lt;- thresholder(rfeMedgtuneprevDS, threshold = seq(0,1,.02))</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2172  485
##         X1  561 2776
##                             
##  Accuracy (average) : 0.8255</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2716  167
##         X1   17  107
##                             
##  Accuracy (average) : 0.9388</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0  761   20
##         X1 1972  254
##                             
##  Accuracy (average) : 0.3375</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-125-1.png" width="1248" style="display: block; margin: auto;" /></p>
<p><em>RFE 14th HUC GBM Tune</em></p>
<pre class="r"><code>#get variable subset from oneSD results
oneR
oneR1
rfe14g$optVariables[1:6]
rfe14gprev$optVariables[1:13]

rec_tune14g &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-cpg30precip,-tpi30agg,-decid30RS,-cad30RS,-stream, new_role = &quot;bring along&quot;) 
 
rec_tune14gprev &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-tpi30agg,-cpg30precip,-decid30RS,-deficitRS,-hdi30RS,-cad30RS,-vv30agg,-twi30agg,-ndwias30agg,-stream,-B2_30agg,-B3_30agg,-B4_30agg,-B8_30agg, new_role = &quot;bring along&quot;) %&gt;% 
  step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, threshold = 0.9, num_comp = 2)
  
rec_tune14gprevDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-tpi30agg,-cpg30precip,-decid30RS,-deficitRS,-hdi30RS,-cad30RS,-vv30agg,-twi30agg,-ndwias30agg,-stream,-B2_30agg,-B3_30agg,-B4_30agg,-B8_30agg, new_role = &quot;bring along&quot;) %&gt;% 
  step_downsample(stream) %&gt;% 
  step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, threshold = 0.9, num_comp = 2)


cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
rfe14gtune &lt;- train(rec_tune14g, data = traintune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indices14tune$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
rfe14gtuneprev &lt;- train(rec_tune14gprev, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indices14tuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
rfe14gtuneprevDS &lt;- train(rec_tune14gprevDS, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indices14tuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

stopCluster(cluster)
registerDoSEQ()

rfe14gtuneThresh &lt;- thresholder(rfe14gtune, threshold = seq(0,1,.02))
rfe14gtuneprevThresh &lt;- thresholder(rfe14gtuneprev, threshold = seq(0,1,.02))
rfe14gtuneprevThreshDS &lt;- thresholder(rfe14gtuneprevDS, threshold = seq(0,1,.02))</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2248  485
##         X1  485 2776
##                             
##  Accuracy (average) : 0.8382</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2670  135
##         X1   63  139
##                             
##  Accuracy (average) : 0.9342</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0    0    0
##         X1 2733  274
##                              
##  Accuracy (average) : 0.09112</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-127-1.png" width="1248" style="display: block; margin: auto;" /></p>
<p><em>RFE Kmeans GBM</em></p>
<pre class="r"><code>#get variable subset from oneSD results
oneR
oneR1
rfeKg$optVariables[1:6]
rfeKgprev$optVariables[1:7]

rec_tuneKg &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-cpg30precip,-tpi30agg,-decid30RS,-cad30RS,-stream, new_role = &quot;bring along&quot;) 
 
rec_tuneKgprev &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-tpi30agg,-cpg30precip,-decid30RS,-deficitRS,-stream,-B2_30agg,-B3_30agg,-B4_30agg,-B8_30agg, new_role = &quot;bring along&quot;) %&gt;% 
  step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, threshold = 0.9, num_comp = 1)
  
rec_tuneKgprevDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-tpi30agg,-cpg30precip,-decid30RS,-deficitRS,-stream,-B2_30agg,-B3_30agg,-B4_30agg,-B8_30agg, new_role = &quot;bring along&quot;) %&gt;% 
  step_downsample(stream) %&gt;% 
  step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, threshold = 0.9, num_comp = 1)

cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
rfeKgtune &lt;- train(rec_tuneKg, data = traintune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indicesKtune$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
rfeKgtuneprev &lt;- train(rec_tuneKgprev, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indicesKtuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
rfeKgtuneprevDS &lt;- train(rec_tuneKgprevDS, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indicesKtuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)
stopCluster(cluster)
registerDoSEQ()

rfeKgtuneThresh &lt;- thresholder(rfeKgtune, threshold = seq(0,1,.02))
rfeKgtuneprevThresh &lt;- thresholder(rfeKgtuneprev, threshold = seq(0,1,.02))
rfeKgtuneprevThreshDS &lt;- thresholder(rfeKgtuneprevDS, threshold = seq(0,1,.02))</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2328  435
##         X1  405 2826
##                             
##  Accuracy (average) : 0.8599</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2725  180
##         X1    8   94
##                             
##  Accuracy (average) : 0.9375</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 1404  113
##         X1 1329  161
##                             
##  Accuracy (average) : 0.5205</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-129-1.png" width="1248" style="display: block; margin: auto;" /></p>
</div>
<div id="rfe-tuned-partial-dependency-plots" class="section level4">
<h4>RFE tuned partial dependency plots</h4>
<p>Now that we’ve tuned both models (rf and gbm) we can start to look at some of the variable dependency plots. This will give us an idea of how the variables are reacting to the response and where the model seems to find it important. What will be interesting is how each structure (12th,14th,blockCV,Kmeans) reacts and also the between balanced and prevalence. We’ll basically just plot all the pdp’s by model type and structure type and variable.</p>
<p><em>Look at accum30 for random forest</em></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-131-1.png" width="1920" style="display: block; margin: auto;" />
<em>Look at accum30 for gbm</em></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-133-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><em>Look at nppmmid30agg for Random Forest</em></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-135-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><em>Look at nppmmid30agg for GBM</em></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-137-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><em>Look at tpi30agg for Random Forest</em></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-139-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><em>Look at tpi30agg for GBM</em></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-141-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><em>Look at cpg30precip for Random Forest</em></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-143-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><em>Look at cpg30precip for GBM</em></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-145-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><em>Look at cad30RS for Random Forest</em></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-147-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><em>Look at cad30RS for GBM</em></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-149-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p>Now the variables are getting scarce between models and structures. However, GBM did have more diversity than random forest that included <code>deficitRS</code> and <code>decid30RS</code>. We will look at those below.</p>
<p><em>Look at decid30RS for GBM</em></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-151-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><em>Look at deficitRS for GBM</em></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-153-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-155-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-157-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-159-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-161-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-163-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-165-1.png" width="1440" style="display: block; margin: auto;" /></p>
<p><br>
After looking at the interactions between these variables there are only a few interactions that I want to look at that include prevalence data. The reason is that most of the pdp’s are reacting the same regardless of balanced or prevalence and only the probability (yhat) is shifted/different. So, from here out will mostly just be balanced data between random forest, gbm, and dependence structures.</p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-167-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-169-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-171-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-173-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-175-1.png" width="1440" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-177-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-179-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-181-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-183-1.png" width="1440" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-185-1.png" width="1440" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-187-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-189-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-191-1.png" width="1920" style="display: block; margin: auto;" /></p>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-193-1.png" width="1920" style="display: block; margin: auto;" /></p>
</div>
<div id="ffs-tuned-random-forest" class="section level3">
<h3>FFS tuned Random Forest</h3>
<p>Just use the same tuning features as with RFE.</p>
<p><em>FFS 12th HUC Random Forest Tune</em></p>
<pre class="r"><code>#get variable subset from oneSD results
library(recipes)
ffs12rf$selectedvars
ffs12rfprev$selectedvars

&quot;accum30&quot;      &quot;decid30RS&quot;    &quot;tpi30agg&quot;     &quot;nppmmid30agg&quot; &quot;deficitRS&quot;    &quot;twi30agg&quot;     &quot;ndvi30yrRS&quot; 
&quot;accum30&quot;     &quot;deficitRS&quot;   &quot;cpg30precip&quot; &quot;hdi30RS&quot;     &quot;vvsd30agg&quot;
levels(traintune$stream) &lt;- c(&quot;X0&quot;,&quot;X1&quot;)

rec_tune12ffs &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-decid30RS,-deficitRS,-twi30agg,-ndvi30yrRS,-stream, new_role = &quot;bring along&quot;)

rec_tune12prevffs &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-cpg30precip,-vvsd30agg,-hdi30RS,-deficitRS,-stream, new_role = &quot;bring along&quot;)
  

rec_tune12prevffsDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  step_downsample(stream) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-cpg30precip,-vvsd30agg,-hdi30RS,-deficitRS,-stream, new_role = &quot;bring along&quot;)


cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
ffs12tune &lt;- train(rec_tune12ffs, data = traintune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:6,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indices12tune$index,
                                       summaryFunction = customRFsum))

set.seed(1234)
ffs12tuneprev &lt;- train(rec_tune12prevffs, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:4,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indices12tuneprev$index,
                                       summaryFunction = customRFsum))

set.seed(1234)
ffs12tuneprevDS &lt;- train(rec_tune12prevffsDS, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:4,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indices12tuneprev$index,
                                       summaryFunction = customRFsum))

stopCluster(cluster)
registerDoSEQ()
ffs12tune$bestTune
ffs12tuneThresh &lt;- thresholder(ffs12tune, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying
ffs12tuneprevThresh &lt;- thresholder(ffs12tuneprev, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying
ffs12tuneprevThreshDS &lt;- thresholder(ffs12tuneprevDS, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2190  504
##         X1  543 2757
##                             
##  Accuracy (average) : 0.8253</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2633  136
##         X1  100  138
##                             
##  Accuracy (average) : 0.9215</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2186   64
##         X1  547  210
##                             
##  Accuracy (average) : 0.7968</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-195-1.png" width="1248" style="display: block; margin: auto;" /></p>
<p><em>FFS BlockCV Medium Random Forest Tune</em></p>
<pre class="r"><code>#get variable subset from oneSD results
library(recipes)
ffsMedrf$selectedvars
ffsMedrfprev$selectedvars

levels(traintune$stream) &lt;- c(&quot;X0&quot;,&quot;X1&quot;)

&quot;accum30&quot;      &quot;decid30RS&quot;    &quot;nppmmid30agg&quot; &quot;cad30RS&quot;      &quot;tpi30agg&quot;     &quot;deficitRS&quot; 
&quot;accum30&quot;      &quot;cpg30precip&quot;  &quot;nppmmid30agg&quot; &quot;cad30RS&quot;      &quot;pca_B1&quot;       &quot;hdi30RS&quot;      &quot;vv30agg&quot;  

rec_tuneMedffs &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-decid30RS,-cad30RS,-deficitRS,-stream, new_role = &quot;bring along&quot;)

rec_tuneMedprevffs &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-hdi30RS,-nppmmid30agg,-cpg30precip,-cad30RS,-vv30agg, -B2_30agg,-B3_30agg,-B4_30agg, -B8_30agg, -stream, new_role = &quot;bring along&quot;) %&gt;% 
  step_center(contains(&quot;_30agg&quot;)) %&gt;% 
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, num_comp = 1)

rec_tuneMedprevffsDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  step_downsample(stream) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-hdi30RS,-nppmmid30agg,-cpg30precip,-cad30RS,-vv30agg, -B2_30agg,-B3_30agg,-B4_30agg, -B8_30agg,-stream, new_role = &quot;bring along&quot;) %&gt;% 
  step_center(contains(&quot;_30agg&quot;)) %&gt;% 
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, num_comp = 1)


cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
ffsMedtune &lt;- train(rec_tuneMedffs, data = traintune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:5,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indicesMedtune$index,
                                       summaryFunction = customRFsum))

set.seed(1234)
ffsMedtuneprev &lt;- train(rec_tuneMedprevffs, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:6,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indicesMedtuneprev$index,
                                       summaryFunction = customRFsum))

set.seed(1234)
ffsMedtuneprevDS &lt;- train(rec_tuneMedprevffsDS, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:6,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indicesMedtuneprev$index,
                                       summaryFunction = customRFsum))

stopCluster(cluster)
registerDoSEQ()

ffsMedtuneThresh &lt;- thresholder(ffsMedtune, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying
ffsMedtuneprevThresh &lt;- thresholder(ffsMedtuneprev, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying
ffsMedtuneprevThreshDS &lt;- thresholder(ffsMedtuneprevDS, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2210  470
##         X1  523 2791
##                             
##  Accuracy (average) : 0.8343</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2663  128
##         X1   70  146
##                             
##  Accuracy (average) : 0.9342</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2193   59
##         X1  540  215
##                             
##  Accuracy (average) : 0.8008</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-197-1.png" width="1248" style="display: block; margin: auto;" /></p>
<pre><code>##    mtry ntree
## 38    5  1100</code></pre>
<pre class="r"><code>#get variable subset from oneSD results
library(recipes)
ffs14rf$selectedvars
ffs14rfprev$selectedvars

levels(traintune$stream) &lt;- c(&quot;X0&quot;,&quot;X1&quot;)

  &quot;accum30&quot;      &quot;decid30RS&quot;    &quot;nppmmid30agg&quot; &quot;ndvi30yrRS&quot;   &quot;tpi30agg&quot;     &quot;cad30RS&quot;      &quot;deficitRS&quot;    &quot;twi30agg&quot; 
  &quot;accum30&quot;      &quot;cpg30precip&quot;  &quot;nppmmid30agg&quot; &quot;cad30RS&quot;      &quot;pca_B1&quot;       &quot;hdi30RS&quot;      &quot;vv30agg&quot; 

rec_tune14ffs &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-tpi30agg,-nppmmid30agg,-decid30RS,-cad30RS,-deficitRS,-ndvi30yrRS,-deficitRS,-twi30agg,-stream, new_role = &quot;bring along&quot;)

rec_tune14prevffs &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-hdi30RS,-nppmmid30agg,-cpg30precip,-cad30RS,-vv30agg, -B2_30agg,-B3_30agg,-B4_30agg, -B8_30agg, -stream, new_role = &quot;bring along&quot;) %&gt;% 
  step_center(contains(&quot;_30agg&quot;)) %&gt;% 
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, num_comp = 1)

rec_tune14prevffsDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  step_downsample(stream) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-hdi30RS,-nppmmid30agg,-cpg30precip,-cad30RS,-vv30agg, -B2_30agg,-B3_30agg,-B4_30agg, -B8_30agg,-stream, new_role = &quot;bring along&quot;) %&gt;% 
  step_center(contains(&quot;_30agg&quot;)) %&gt;% 
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, num_comp = 1)


cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
ffs14tune &lt;- train(rec_tune14ffs, data = traintune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:7,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indices14tune$index,
                                       summaryFunction = customRFsum))

set.seed(1234)
ffs14tuneprev &lt;- train(rec_tune14prevffs, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:6,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indices14tuneprev$index,
                                       summaryFunction = customRFsum))

set.seed(1234)
ffs14tuneprevDS &lt;- train(rec_tune14prevffsDS, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:6,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indices14tuneprev$index,
                                       summaryFunction = customRFsum))

stopCluster(cluster)
registerDoSEQ()

ffs14tuneThresh &lt;- thresholder(ffs14tune, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying
ffs14tuneprevThresh &lt;- thresholder(ffs14tuneprev, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying
ffs14tuneprevThreshDS &lt;- thresholder(ffs14tuneprevDS, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2243  495
##         X1  490 2766
##                             
##  Accuracy (average) : 0.8357</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2663  128
##         X1   70  146
##                             
##  Accuracy (average) : 0.9342</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2181   51
##         X1  552  223
##                             
##  Accuracy (average) : 0.7995</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-199-1.png" width="1248" style="display: block; margin: auto;" /></p>
<p><em>FFS Kmeans Random Forest</em></p>
<pre class="r"><code>#get variable subset from oneSD results
library(recipes)
ffsKrf$selectedvars
ffsKrfprev$selectedvars

levels(traintune$stream) &lt;- c(&quot;X0&quot;,&quot;X1&quot;)

 &quot;accum30&quot;      &quot;nppmmid30agg&quot; &quot;cpg30precip&quot;  &quot;cad30RS&quot;      &quot;pca_B1&quot;       &quot;deficitRS&quot;    &quot;ndvi30yrRS&quot;  
 
 &quot;accum30&quot;      &quot;cpg30precip&quot;  &quot;nppmmid30agg&quot; &quot;cad30RS&quot;      &quot;pca_B1&quot;       &quot;hdi30RS&quot;      &quot;vv30agg&quot;

rec_tuneKffs &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-cpg30precip,-nppmmid30agg,-deficitRS,-cad30RS,-ndvi30yrRS,-B2_30agg,-B3_30agg,-B4_30agg, -B8_30agg,-stream, new_role = &quot;bring along&quot;)%&gt;% 
  step_center(contains(&quot;_30agg&quot;)) %&gt;% 
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, num_comp = 1)

rec_tuneKprevffs &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-hdi30RS,-nppmmid30agg,-cpg30precip,-cad30RS,-vv30agg, -B2_30agg,-B3_30agg,-B4_30agg, -B8_30agg, -stream, new_role = &quot;bring along&quot;) %&gt;% 
  step_center(contains(&quot;_30agg&quot;)) %&gt;% 
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, num_comp = 1)

rec_tuneKprevffsDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  step_downsample(stream) %&gt;% 
  update_role(sb12,sb14,sbMed,spatial_cluster, HUC12, HUC14, coords.x1,coords.x2, new_role = &quot;bring along&quot;) %&gt;% 
  update_role(-accum30,-hdi30RS,-nppmmid30agg,-cpg30precip,-cad30RS,-vv30agg, -B2_30agg,-B3_30agg,-B4_30agg, -B8_30agg,-stream, new_role = &quot;bring along&quot;) %&gt;% 
  step_center(contains(&quot;_30agg&quot;)) %&gt;% 
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, num_comp = 1)


cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
ffsKtune &lt;- train(rec_tuneKffs, data = traintune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:6,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indicesKtune$index,
                                       summaryFunction = customRFsum))

set.seed(1234)
ffsKtuneprev &lt;- train(rec_tuneKprevffs, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:6,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indicesKtuneprev$index,
                                       summaryFunction = customRFsum))

set.seed(1234)
ffsKtuneprevDS &lt;- train(rec_tuneKprevffsDS, data = trainprevtune,
              method = customRF,
              metric = &quot;AUC&quot;,
              tuneGrid = expand.grid(mtry = 1:6,ntree=seq(100,1500,200)),
              trControl = trainControl(method = &quot;repeatedcv&quot;,
                                       repeats = 5,
                                       classProbs = TRUE,
                                       savePredictions = &#39;all&#39;,
                                       index = indicesKtuneprev$index,
                                       summaryFunction = customRFsum))

stopCluster(cluster)
registerDoSEQ()

ffsKtuneThresh &lt;- thresholder(ffsKtune, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying
ffsKtuneprevThresh &lt;- thresholder(ffsKtuneprev, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying
ffsKtuneprevThreshDS &lt;- thresholder(ffsKtuneprevDS, threshold = seq(0,1,.02)) #we&#39;ll use as threshold for classifying</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2356  405
##         X1  377 2856
##                             
##  Accuracy (average) : 0.8695</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2663  128
##         X1   70  146
##                             
##  Accuracy (average) : 0.9342</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2157   50
##         X1  576  224
##                             
##  Accuracy (average) : 0.7918</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-201-1.png" width="1248" style="display: block; margin: auto;" /></p>
<div id="ffs-tuning-gbm" class="section level4">
<h4>FFS tuning GBM</h4>
<p><em>FFS 12th HUC GBM Tune</em></p>
<pre class="r"><code>#we&#39;ll use this tunegrid for all gbm models
gbmGrid &lt;- expand.grid(interaction.depth = c(1,2,4,6,8), n.trees = c(500,1000,1500,2000,3000), shrinkage = c(0.001,.05,0.1,0.2,0.5), n.minobsinnode = c(10,15,25))
#get variable names from ffs

ffs12g$finalModel$var.names
ffs12gprev$finalModel$var.names

&quot;accum30&quot;   &quot;deficitRS&quot; &quot;cad30RS&quot;   &quot;pca_B1&quot;
&quot;accum30&quot;   &quot;deficitRS&quot; &quot;twi30agg&quot;  &quot;cad30RS&quot;  

rec_tune12gffs &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(-accum30,-deficitRS,-cad30RS,-B2_30agg,-B3_30agg,-B4_30agg,-B8_30agg,-stream, new_role = &quot;bring along&quot;) %&gt;% 
step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, num_comp = 1)

rec_tune12gffsprev &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(-accum30,-cad30RS,-twi30agg,-deficitRS,-stream, new_role = &quot;bring along&quot;) 

rec_tune12gffsprevDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
 update_role(-accum30,-cad30RS,-twi30agg,-deficitRS,-stream, new_role = &quot;bring along&quot;) %&gt;% 
  step_downsample(stream)
  
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
ffs12gtune &lt;- train(rec_tune12gffs, data = traintune,
              method = &quot;gbm&quot;,
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indices12tune$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
ffs12gtuneprev &lt;- train(rec_tune12gffsprev, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indices12tuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
ffs12gtuneprevDS &lt;- train(rec_tune12gffsprevDS, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indices12tuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)
stopCluster(cluster)
registerDoSEQ()

ffs12gtuneThresh &lt;- thresholder(ffs12gtune, threshold = seq(0,1,.02))
ffs12gtuneprevThresh &lt;- thresholder(ffs12gtuneprev, threshold = seq(0,1,.02))
ffs12gtuneprevThreshDS &lt;- thresholder(ffs12gtuneprevDS, threshold = seq(0,1,.02))</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2170  575
##         X1  563 2686
##                             
##  Accuracy (average) : 0.8101</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2666  146
##         X1   67  128
##                             
##  Accuracy (average) : 0.9292</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2732  272
##         X1    1    2
##                             
##  Accuracy (average) : 0.9092</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-203-1.png" width="1248" style="display: block; margin: auto;" /></p>
<p><em>FFS BlockCV Medium GBM Tune</em></p>
<pre class="r"><code>#we&#39;ll use this tunegrid for all gbm models
gbmGrid &lt;- expand.grid(interaction.depth = c(1,2,4,6,8), n.trees = c(500,1000,1500,2000,3000), shrinkage = c(0.001,.05,0.1,0.2,0.5), n.minobsinnode = c(10,15,25))
#get variable names from ffs

ffsMedg$finalModel$var.names
ffsMedgprev$finalModel$var.names

&quot;accum30&quot;      &quot;deficitRS&quot;    &quot;tpi30agg&quot;     &quot;nppmmid30agg&quot; &quot;pca_B1&quot;       &quot;decid30RS&quot;    &quot;twi30agg&quot; 
&quot;accum30&quot;      &quot;nppmmid30agg&quot; &quot;twi30agg&quot;    

rec_tuneMedgffs &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(-accum30,-deficitRS,-tpi30agg,-nppmmid30agg,-decid30RS,-twi30agg,-B2_30agg,-B3_30agg,-B4_30agg,-B8_30agg,-stream, new_role = &quot;bring along&quot;) %&gt;% 
step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, num_comp = 1)

rec_tuneMedgffsprev &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-twi30agg,-stream, new_role = &quot;bring along&quot;) 

rec_tuneMedgffsprevDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  step_downsample(stream) %&gt;% 
 update_role(-accum30,-nppmmid30agg,-twi30agg,-stream, new_role = &quot;bring along&quot;)
  
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
ffsMedgtune &lt;- train(rec_tuneMedgffs, data = traintune,
              method = &quot;gbm&quot;,
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indicesMedtune$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
ffsMedgtuneprev &lt;- train(rec_tuneMedgffsprev, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indicesMedtuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
ffsMedgtuneprevDS &lt;- train(rec_tuneMedgffsprevDS, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indicesMedtuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)
stopCluster(cluster)
registerDoSEQ()

ffsMedgtuneThresh &lt;- thresholder(ffsMedgtune, threshold = seq(0,1,.02))
ffsMedgtuneprevThresh &lt;- thresholder(ffsMedgtuneprev, threshold = seq(0,1,.02))
ffsMedgtuneprevThreshDS &lt;- thresholder(ffsMedgtuneprevDS, threshold = seq(0,1,.02))</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2218  485
##         X1  515 2776
##                             
##  Accuracy (average) : 0.8332</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2667  145
##         X1   66  129
##                             
##  Accuracy (average) : 0.9298</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 1928  173
##         X1  805  101
##                             
##  Accuracy (average) : 0.6748</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-205-1.png" width="1248" style="display: block; margin: auto;" /></p>
<p><em>FFS 14th HUC GBM Tune</em></p>
<pre class="r"><code>#we&#39;ll use this tunegrid for all gbm models
gbmGrid &lt;- expand.grid(interaction.depth = c(1,2,4,6,8), n.trees = c(500,1000,1500,2000,3000), shrinkage = c(0.001,.05,0.1,0.2,0.5), n.minobsinnode = c(10,15,25))
#get variable names from ffs

ffs14g$finalModel$var.names
ffs14gprev$finalModel$var.names

&quot;accum30&quot;      &quot;deficitRS&quot;    &quot;nppmmid30agg&quot; &quot;tpi30agg&quot;     &quot;pca_B1&quot; 
&quot;accum30&quot;      &quot;nppmmid30agg&quot; &quot;twi30agg&quot; 

rec_tune14gffs &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(-accum30,-deficitRS,-nppmmid30agg,-tpi30agg,-B2_30agg,-B3_30agg,-B4_30agg,-B8_30agg,-stream, new_role = &quot;bring along&quot;) %&gt;% 
step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, num_comp = 1)

rec_tune14gffsprev &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(-accum30,-nppmmid30agg,-twi30agg,-stream, new_role = &quot;bring along&quot;) 

rec_tune14gffsprevDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
 update_role(-accum30,-nppmmid30agg,-twi30agg,-stream, new_role = &quot;bring along&quot;) %&gt;% 
  step_downsample(stream)
  
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
ffs14gtune &lt;- train(rec_tune14gffs, data = traintune,
              method = &quot;gbm&quot;,
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indices14tune$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
ffs14gtuneprev &lt;- train(rec_tune14gffsprev, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indices14tuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
ffs14gtuneprevDS &lt;- train(rec_tune14gffsprevDS, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indices14tuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)
stopCluster(cluster)
registerDoSEQ()

ffs14gtuneThresh &lt;- thresholder(ffs14gtune, threshold = seq(0,1,.02))
ffs14gtuneprevThresh &lt;- thresholder(ffs14gtuneprev, threshold = seq(0,1,.02))
ffs14gtuneprevThreshDS &lt;- thresholder(ffs14gtuneprevDS, threshold = seq(0,1,.02))</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2250  501
##         X1  483 2760
##                             
##  Accuracy (average) : 0.8358</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 2667  145
##         X1   66  129
##                             
##  Accuracy (average) : 0.9298</code></pre>
<pre><code>## Cross-Validated (10 fold, repeated 5 times) Confusion Matrix 
## 
## (entries are un-normalized aggregated counts)
##  
##           Reference
## Prediction   X0   X1
##         X0 1928  173
##         X1  805  101
##                             
##  Accuracy (average) : 0.6748</code></pre>
<p><img src="/project/walkingLongFormat_files/figure-html/unnamed-chunk-207-1.png" width="1248" style="display: block; margin: auto;" /></p>
<p><em>FFS Kmeans GBM Tune</em></p>
<pre class="r"><code>#we&#39;ll use this tunegrid for all gbm models
gbmGrid &lt;- expand.grid(interaction.depth = c(1,2,4,6,8), n.trees = c(500,1000,1500,2000,3000), shrinkage = c(0.001,.05,0.1,0.2,0.5), n.minobsinnode = c(10,15,25))
#get variable names from ffs

ffsKg$finalModel$var.names
ffsKgprev$finalModel$var.names

&quot;accum30&quot;   &quot;deficitRS&quot; &quot;cad30RS&quot;   &quot;pca_B1&quot;
&quot;accum30&quot;   &quot;deficitRS&quot; &quot;twi30agg&quot;  &quot;cad30RS&quot;  

rec_tuneKgffs &lt;-   recipe(stream ~ ., data = traintune) %&gt;% 
  update_role(-accum30,-deficitRS,-cad30RS,-B2_30agg,-B3_30agg,-B4_30agg,-B8_30agg,-stream, new_role = &quot;bring along&quot;) %&gt;% 
step_center(contains(&quot;_30agg&quot;))  %&gt;%
  step_scale(contains(&quot;_30agg&quot;)) %&gt;% 
  step_pca(contains(&quot;_30agg&quot;), prefix = &quot;pca_B&quot;, num_comp = 1)

rec_tuneKgffsprev &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
  update_role(-accum30,-cad30RS,-twi30agg,-deficitRS,-stream, new_role = &quot;bring along&quot;) 

rec_tuneKgffsprevDS &lt;-   recipe(stream ~ ., data = trainprevtune) %&gt;% 
 update_role(-accum30,-cad30RS,-twi30agg,-deficitRS,-stream, new_role = &quot;bring along&quot;)
  
cluster &lt;- makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)

set.seed(1234)
ffsKgtune &lt;- train(rec_tuneKgffs, data = traintune,
              method = &quot;gbm&quot;,
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indicesKtune$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
ffsKgtuneprev &lt;- train(rec_tuneKgffsprev, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indicesKtuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)

set.seed(1234)
ffsKgtuneprevDS &lt;- train(rec_tuneKgffsprevDS, data = trainprevtune,
              method = &quot;gbm&quot;, 
                 metric = &quot;AUC&quot;, distribution = &quot;bernoulli&quot;,
                  trControl = trainControl(method = &quot;repeatedcv&quot;,
                                           repeats = 5,
                                           classProbs = TRUE,
                                           savePredictions = &#39;all&#39;,
                                           index = indicesKtuneprev$index,
                                           summaryFunction = multiClassSummary),
              tuneGrid = gbmGrid)
stopCluster(cluster)
registerDoSEQ()

ffsKgtuneThresh &lt;- thresholder(ffsKgtune, threshold = seq(0,1,.02))
ffsKgtuneprevThresh &lt;- thresholder(ffsKgtuneprev, threshold = seq(0,1,.02))
ffsKgtuneprevThreshDS &lt;- thresholder(ffsKgtuneprevDS, threshold = seq(0,1,.02))</code></pre>
</div>
</div>
</div>
<div id="model-assessment" class="section level2">
<h2>Model Assessment</h2>
<p>Model Assessment</p>
<p>lsakdjfsalkdjf
as;ldfkjasldfj</p>
</div>
</div>
</div>
<div id="discussionresults" class="section level1">
<h1>Discussion/Results</h1>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<p><strong>Bibliography</strong></p>
<div id="refs" class="references">
<div id="ref-altman1994diagnostic">
<p>Altman, Douglas G, and J Martin Bland. 1994. “Diagnostic Tests. 1: Sensitivity and Specificity.” <em>BMJ: British Medical Journal</em> 308 (6943): 1552.</p>
</div>
<div id="ref-bahn2013testing">
<p>Bahn, Volker, and Brian J McGill. 2013. “Testing the Predictive Performance of Distribution Models.” <em>Oikos</em> 122 (3): 321–31.</p>
</div>
<div id="ref-beven1979physically">
<p>BEVEN, Keith J, and Michael J Kirkby. 1979. “A Physically Based, Variable Contributing Area Model of Basin Hydrology/Un Modèle à Base Physique de Zone d’appel Variable de L’hydrologie Du Bassin Versant.” <em>Hydrological Sciences Journal</em> 24 (1): 43–69.</p>
</div>
<div id="ref-breiman1984classification">
<p>Breiman, Leo, Jerome Friedman, Charles J Stone, and Richard A Olshen. 1984. <em>Classification and Regression Trees</em>. CRC press.</p>
</div>
<div id="ref-dobrowski2013climate">
<p>Dobrowski, Solomon Z, John Abatzoglou, Alan K Swanson, Jonathan A Greenberg, Alison R Mynsberge, Zachary A Holden, and Michael K Schwartz. 2013. “The Climate Velocity of the Contiguous U Nited S Tates During the 20th Century.” <em>Global Change Biology</em> 19 (1): 241–51.</p>
</div>
<div id="ref-elith2008working">
<p>Elith, Jane, John R Leathwick, and Trevor Hastie. 2008. “A Working Guide to Boosted Regression Trees.” <em>Journal of Animal Ecology</em> 77 (4): 802–13.</p>
</div>
<div id="ref-friedman2001elements">
<p>Friedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2001. <em>The Elements of Statistical Learning</em>. Vol. 1. 10. Springer series in statistics New York.</p>
</div>
<div id="ref-gesch2009national">
<p>Gesch, Dean, Gayla Evans, James Mauck, John Hutchinson, William J Carswell Jr, and others. 2009. “The National Map—Elevation.” <em>US Geological Survey Fact Sheet</em> 3053 (4).</p>
</div>
<div id="ref-gorelick2017google">
<p>Gorelick, Noel, Matt Hancher, Mike Dixon, Simon Ilyushchenko, David Thau, and Rebecca Moore. 2017. “Google Earth Engine: Planetary-Scale Geospatial Analysis for Everyone.” <em>Remote Sensing of Environment</em>. <a href="https://doi.org/10.1016/j.rse.2017.06.031">https://doi.org/10.1016/j.rse.2017.06.031</a>.</p>
</div>
<div id="ref-hird2017google">
<p>Hird, Jennifer, Evan DeLancey, Gregory McDermid, and Jahan Kariyeva. 2017. “Google Earth Engine, Open-Access Satellite Data, and Machine Learning in Support of Large-Area Probabilistic Wetland Mapping.” <em>Remote Sensing</em> 9 (12): 1315.</p>
</div>
<div id="ref-HoldenPrep">
<p>Holden, A. Swanson, Z. A., and others. In prep. “Using Climatic and Biophysical Variables to Model the Presence and Severity of Root Disease Across the U.s. Northern Rocky Mountains.”</p>
</div>
<div id="ref-hoylman2019climatic">
<p>Hoylman, Zachary H, Kelsey G Jencso, Jia Hu, Zachary A Holden, Justin T Martin, and W Payton Gardner. 2019. “The Climatic Water Balance and Topography Control Spatial Patterns of Atmospheric Demand, Soil Moisture, and Shallow Subsurface Flow.” <em>Water Resources Research</em> 55 (3): 2370–89.</p>
</div>
<div id="ref-hoylman2018hillslope">
<p>Hoylman, Zachary H, Kelsey G Jencso, Jia Hu, Justin T Martin, Zachary A Holden, Carl A Seielstad, and Eric M Rowell. 2018. “Hillslope Topography Mediates Spatial Patterns of Ecosystem Sensitivity to Climate.” <em>Journal of Geophysical Research: Biogeosciences</em> 123 (2): 353–71.</p>
</div>
<div id="ref-ives2006statistics">
<p>Ives, Anthony R, and Jun Zhu. 2006. “Statistics for Correlated Data: Phylogenies, Space, and Time.” <em>Ecological Applications</em> 16 (1): 20–32.</p>
</div>
<div id="ref-jaeger2019probability">
<p>Jaeger, KL, R Sando, Ryan R McShane, Jason B Dunham, DP Hockman-Wert, Kendra E Kaiser, K Hafen, JC Risley, and KW Blasch. 2019. “Probability of Streamflow Permanence Model (Prosper): A Spatially Continuous Model of Annual Streamflow Permanence Throughout the Pacific Northwest.” <em>Journal of Hydrology X</em> 2: 100005.</p>
</div>
<div id="ref-james2013introduction">
<p>James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Vol. 112. Springer.</p>
</div>
<div id="ref-kaufman2012leakage">
<p>Kaufman, Shachar, Saharon Rosset, Claudia Perlich, and Ori Stitelman. 2012. “Leakage in Data Mining: Formulation, Detection, and Avoidance.” <em>ACM Transactions on Knowledge Discovery from Data (TKDD)</em> 6 (4): 1–21.</p>
</div>
<div id="ref-kuhn2013applied">
<p>Kuhn, Max, and Kjell Johnson. 2013. <em>Applied Predictive Modeling</em>. Vol. 26. Springer.</p>
</div>
<div id="ref-lidberg2020using">
<p>Lidberg, William, Mats Nilsson, and Anneli Ågren. 2020. “Using Machine Learning to Generate High-Resolution Wet Area Maps for Planning Forest Management: A Study in a Boreal Forest Landscape.” <em>Ambio</em> 49 (2): 475–86.</p>
</div>
<div id="ref-lutz2010climatic">
<p>Lutz, James A, Jan W Van Wagtendonk, and Jerry F Franklin. 2010. “Climatic Water Deficit, Tree Species Ranges, and Climate Change in Yosemite National Park.” <em>Journal of Biogeography</em> 37 (5): 936–50.</p>
</div>
<div id="ref-matloff2017statistical">
<p>Matloff, Norman. 2017. <em>Statistical Regression and Classification: From Linear Models to Machine Learning</em>. CRC Press.</p>
</div>
<div id="ref-meyer2018improving">
<p>Meyer, Hanna, Christoph Reudenbach, Tomislav Hengl, Marwan Katurji, and Thomas Nauss. 2018. “Improving Performance of Spatio-Temporal Machine Learning Models Using Forward Feature Selection and Target-Oriented Validation.” <em>Environmental Modelling &amp; Software</em> 101: 1–9.</p>
</div>
<div id="ref-meyer2019importance">
<p>Meyer, Hanna, Christoph Reudenbach, Stephan Wöllauer, and Thomas Nauss. 2019. “Importance of Spatial Predictor Variable Selection in Machine Learning Applications–Moving from Data Reproduction to Spatial Prediction.” <em>Ecological Modelling</em> 411: 108815.</p>
</div>
<div id="ref-pelletier2018way">
<p>Pelletier, Jon D, Greg A Barron-Gafford, Hugo Gutiérrez-Jurado, Eve-Lyn S Hinckley, Erkan Istanbulluoglu, Luke A McGuire, Guo-Yue Niu, et al. 2018. “Which Way Do You Lean? Using Slope Aspect Variations to Understand Critical Zone Processes and Feedbacks.” <em>Earth Surface Processes and Landforms</em> 43 (5): 1133–54.</p>
</div>
<div id="ref-radula2018topographic">
<p>Raduła, Małgorzata W, Tomasz H Szymura, and Magdalena Szymura. 2018. “Topographic Wetness Index Explains Soil Moisture Better Than Bioindication with Ellenberg’s Indicator Values.” <em>Ecological Indicators</em> 85: 172–79.</p>
</div>
<div id="ref-roberts2017cross">
<p>Roberts, David R, Volker Bahn, Simone Ciuti, Mark S Boyce, Jane Elith, Gurutzeta Guillera-Arroita, Severin Hauenstein, et al. 2017. “Cross-Validation Strategies for Data with Temporal, Spatial, Hierarchical, or Phylogenetic Structure.” <em>Ecography</em> 40 (8): 913–29.</p>
</div>
<div id="ref-robinson2018terrestrial">
<p>Robinson, Nathaniel P, Brady W Allred, William K Smith, Matthew O Jones, Alvaro Moreno, Tyler A Erickson, David E Naugle, and Steven W Running. 2018. “Terrestrial Primary Production for the Conterminous United States Derived from Landsat 30 M and Modis 250 M.” <em>Remote Sensing in Ecology and Conservation</em> 4 (3): 264–80.</p>
</div>
<div id="ref-sando2018cpg">
<p>R. Sando, K. E. Kaiser, T. D. Olsen. 2018. “Probability Fo Streamflow Permanence (Prosper) Continuous Parameter Grids (Cpgs).”</p>
</div>
<div id="ref-sando2015predicting">
<p>Sando, Roy, and Kyle W Blasch. 2015. “Predicting Alpine Headwater Stream Intermittency: A Case Study in the Northern Rocky Mountains.” <em>Ecohydrology &amp; Hydrobiology</em> 15 (2): 68–80.</p>
</div>
<div id="ref-sorensen2006calculation">
<p>Sörensen, Rasmus, Ursula Zinko, and Jan Seibert. 2006. “On the Calculation of the Topographic Wetness Index: Evaluation of Different Methods Based on Field Observations.” <em>Hydrology and Earth System Sciences Discussions</em> 10 (1): 101–12.</p>
</div>
<div id="ref-stephenson1998actual">
<p>Stephenson, Nathan. 1998. “Actual Evapotranspiration and Deficit: Biologically Meaningful Correlates of Vegetation Distribution Across Spatial Scales.” <em>Journal of Biogeography</em> 25 (5): 855–70.</p>
</div>
<div id="ref-S1hird2017google">
<p>Supplementary Material (Code S1) to: Hird, Jennifer, Evan DeLancey, Gregory McDermid, and Jahan Kariyeva. 2017. “Google Earth Engine, Open-Access Satellite Data, and Machine Learning in Support of Large-Area Probabilistic Wetland Mapping.” <em>Remote Sensing</em> 9 (12): 1315.</p>
</div>
<div id="ref-tarboton2013taudem">
<p>Tarboton, David G. 2013. “TauDEM 5.2 Guide to Using the Taudem Command Line Functions for Taudem Multi-File.”</p>
</div>
<div id="ref-team2014language">
<p>Team, R Core. 2014. “A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing.” ISBN 3-900051-07-0. http://www. R-project. org.</p>
</div>
<div id="ref-valavi2018blockcv">
<p>Valavi, Roozbeh, Jane Elith, Jose J Lahoz-Monfort, and Gurutzeta Guillera-Arroita. 2018. “BlockCV: An R Package for Generating Spatially or Environmentally Separated Folds for K-Fold Cross-Validation of Species Distribution Models.” <em>bioRxiv</em>, 357798.</p>
</div>
<div id="ref-stat2011thumb">
<p>Van Bell, Gerald. 2011. <em>Statistical Rules of Thumb</em>. John Wiley &amp; Sons.</p>
</div>
</div>
</div>

</div>

        <footer class="post-footer clearfix">
    

    <div class="share">
        
            <a class="icon-twitter" href="https://twitter.com/share?text=Stream%20Occurence&url=%2fproject%2fwalkinglongformat%2f"
                onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fa fa-twitter"></i>
                <span class="hidden">Twitter</span>
            </a>
        

        
            <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=%2fproject%2fwalkinglongformat%2f"
                onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                <i class="fa fa-facebook"></i>
                <span class="hidden">Facebook</span>
            </a>
        

        
            <a class="icon-google-plus" href="https://plus.google.com/share?url=%2fproject%2fwalkinglongformat%2f"
              onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
              <i class="fa fa-google-plus"></i>
                <span class="hidden">Google+</span>
            </a>
        
        
    </div>
</footer>
    </article>
</div>

            </div>
        </div>

        <footer class="footer">
            <div class="container">
                <div class="site-title-wrapper">
                    <h1 class="site-title">
                        <a title="Ghostwriter example" href="/">Ghostwriter example</a>
                    </h1>
                    <a class="button-square button-jump-top js-jump-top" href="#">
                        <i class="fa fa-angle-up"></i>
                    </a>
                </div>

                <p class="footer-copyright">
                    <span>&copy; 2015 / Powered by <a href="https://gohugo.io/">Hugo</a></span>
                </p>
                <p class="footer-copyright">
                    <span><a href="https://github.com/roryg/ghostwriter">Ghostwriter theme</a> By <a href="http://jollygoodthemes.com">JollyGoodThemes</a></span>
                    <span>/ <a href="https://github.com/jbub/ghostwriter">Ported</a> to Hugo By <a href="https://github.com/jbub">jbub</a></span>
                </p>
            </div>
        </footer>

        <script src="/js/jquery-1.11.3.min.js"></script>
        <script src="/js/jquery.fitvids.js"></script>
        <script src="/js/scripts.js"></script>
    </body>
</html>

